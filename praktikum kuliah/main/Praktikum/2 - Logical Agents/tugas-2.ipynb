{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Laporan Praktikum 2 – Kecerdasan Komputasional  \n",
    "## Proof by Resolution, Forward & Backward Chaining, dan First-Order Logic  \n",
    "\n",
    "\n",
    "### Identitas Mahasiswa\n",
    "- Nama  : Wayan Raditya Putra  \n",
    "- NRP   : 5054241029  \n",
    "- Program Studi : Rekayasa Kecerdasan Artifisial\n",
    "- Angkatan : 2024  \n",
    "\n",
    "\n",
    "### Tujuan Praktikum\n",
    "Praktikum ini bertujuan untuk:  \n",
    "1. Memahami konsep dasar Proof by Resolution sebagai teknik inferensi dalam logika.  \n",
    "2. Mempelajari mekanisme Forward Chaining dan Backward Chaining untuk penalaran berbasis aturan.  \n",
    "3. Mengenal representasi First-Order Logic (FOL) dan bagaimana FOL digunakan dalam basis pengetahuan.  \n",
    "4. Mengimplementasikan berbagai teknik inferensi untuk menyelesaikan permasalahan berbasis logika komputasional.  \n",
    "\n",
    "\n",
    "### Deskripsi Singkat\n",
    "Pada praktikum kedua ini, mahasiswa diminta untuk:  \n",
    "- Menyusun representasi basis pengetahuan dalam bentuk proposisi maupun logika orde pertama.  \n",
    "- Menerapkan teknik inferensi seperti resolution, forward chaining, backward chaining.  \n",
    "- Melakukan percobaan terhadap kasus sederhana untuk melihat bagaimana sistem inferensi menghasilkan kesimpulan dari basis pengetahuan.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalasi dan Import Library\n",
    "\n",
    "**Tujuan:**  \n",
    "Menyiapkan library dan modul yang diperlukan sebelum menjalankan praktikum. Pada tahap ini dilakukan instalasi paket eksternal serta import fungsi-fungsi yang sudah tersedia di file pendukung.\n",
    "\n",
    "```python\n",
    "%pip install ipythonblocks\n",
    "%pip install qpsolvers\n",
    "\n",
    "from utils import *\n",
    "from logic import *\n",
    "from notebook import psource\n",
    "````\n",
    "**Penjelasan:**\n",
    "\n",
    "* `%pip install ipythonblocks` → menginstal library **ipythonblocks** yang digunakan untuk menampilkan blok warna pada notebook.\n",
    "* `%pip install qpsolvers` → menginstal library **qpsolvers** yang digunakan untuk menyelesaikan masalah Quadratic Programming.\n",
    "* `from utils import *` → mengimpor seluruh fungsi dari file `utils.py` yang berisi kumpulan fungsi bantu.\n",
    "* `from logic import *` → mengimpor seluruh fungsi dari file `logic.py` yang berisi implementasi logika proposisional dan inference.\n",
    "* `from notebook import psource` → mengimpor fungsi `psource` dari `notebook.py`, yang digunakan untuk menampilkan source code suatu fungsi langsung di notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipythonblocks in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (1.9.1)\n",
      "Requirement already satisfied: ipython>=4.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipythonblocks) (9.5.0)\n",
      "Requirement already satisfied: notebook>=4.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipythonblocks) (7.4.5)\n",
      "Requirement already satisfied: requests>=1.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipythonblocks) (2.32.5)\n",
      "Requirement already satisfied: colorama in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (0.4.6)\n",
      "Requirement already satisfied: decorator in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (2.19.2)\n",
      "Requirement already satisfied: stack_data in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=4.0->ipythonblocks) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jedi>=0.16->ipython>=4.0->ipythonblocks) (0.8.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from notebook>=4.0->ipythonblocks) (2.17.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from notebook>=4.0->ipythonblocks) (2.27.3)\n",
      "Requirement already satisfied: jupyterlab<4.5,>=4.4.5 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from notebook>=4.0->ipythonblocks) (4.4.7)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from notebook>=4.0->ipythonblocks) (0.2.4)\n",
      "Requirement already satisfied: tornado>=6.2.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from notebook>=4.0->ipythonblocks) (6.5.2)\n",
      "Requirement already satisfied: anyio>=3.1.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (4.10.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (25.1.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (3.1.6)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (5.8.1)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (5.10.4)\n",
      "Requirement already satisfied: packaging>=22.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (25.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.22.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (3.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (27.0.2)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (2.0.5)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (0.28.1)\n",
      "Requirement already satisfied: ipykernel!=6.30.0,>=6.5.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (6.30.1)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (2.3.0)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (80.9.0)\n",
      "Requirement already satisfied: certifi in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (1.0.9)\n",
      "Requirement already satisfied: idna in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (0.16.0)\n",
      "Requirement already satisfied: babel>=2.10 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.0->ipythonblocks) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.0->ipythonblocks) (0.12.1)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.0->ipythonblocks) (4.25.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (4.15.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (25.1.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (1.8.16)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.7 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (7.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jinja2>=3.0.3->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.0->ipythonblocks) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.0->ipythonblocks) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.0->ipythonblocks) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.0->ipythonblocks) (0.27.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (4.4.0)\n",
      "Requirement already satisfied: pywin32>=300 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (311)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (3.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.1.1)\n",
      "Requirement already satisfied: fqdn in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.5.1)\n",
      "Requirement already satisfied: isoduration in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.1.0)\n",
      "Requirement already satisfied: uri-template in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (24.11.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (4.13.5)\n",
      "Requirement already satisfied: bleach!=5.0.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.5.1)\n",
      "Requirement already satisfied: webencodings in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (2.21.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from requests>=1.0->ipythonblocks) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from requests>=1.0->ipythonblocks) (2.5.0)\n",
      "Requirement already satisfied: lark>=1.2.2 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.2.2)\n",
      "Requirement already satisfied: cffi>=1.0.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.17.1)\n",
      "Requirement already satisfied: pycparser in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (2.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (2.8)\n",
      "Requirement already satisfied: arrow>=0.15.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (2.9.0.20250822)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from stack_data->ipython>=4.0->ipythonblocks) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from stack_data->ipython>=4.0->ipythonblocks) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from stack_data->ipython>=4.0->ipythonblocks) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: qpsolvers in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (4.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from qpsolvers) (2.3.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from qpsolvers) (1.16.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipythonblocks\n",
    "%pip install qpsolvers\n",
    "from utils import *\n",
    "from logic import *\n",
    "from notebook import psource\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferensi pada Basis Pengetahuan Proposisional\n",
    "\n",
    "**Tujuan:**  \n",
    "Pada bagian ini kita akan mempelajari dua teknik utama yang digunakan untuk memeriksa apakah suatu kalimat (sentence) dapat di-*entail* oleh sebuah basis pengetahuan (`KB`).  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof by Resolution\n",
    "\n",
    "Tujuan kita adalah memeriksa apakah $KB \\vDash \\alpha$, yaitu apakah $KB \\implies \\alpha$ bernilai benar di setiap model.  \n",
    "\n",
    "Contoh: kita ingin memeriksa apakah $P \\implies Q$ valid.  \n",
    "Untuk itu kita periksa keterpuasan dari $\\neg (P \\implies Q)$, yang bisa ditulis ulang menjadi:  \n",
    "\n",
    "$$\n",
    "P \\land \\neg Q\n",
    "$$\n",
    "\n",
    "Jika ekspresi $P \\land \\neg Q$ **tidak terpuaskan (unsatisfiable)**, maka $P \\implies Q$ pasti benar di semua model.  \n",
    "\n",
    "\n",
    "### Konsep Dasar\n",
    "\n",
    "Teknik ini dikenal sebagai **pembuktian dengan kontradiksi** (*proof by contradiction*).  \n",
    "Langkahnya: kita mengasumsikan bahwa $\\alpha$ salah, lalu menunjukkan bahwa asumsi ini menimbulkan kontradiksi dengan fakta-fakta dalam $KB$.  \n",
    "\n",
    "\n",
    "### Aturan Resolusi\n",
    "\n",
    "Aturan resolusi berbunyi:  \n",
    "\n",
    "$$\n",
    "(l_1 \\lor \\dots \\lor l_k), \\quad (m_1 \\lor \\dots \\lor m_n), \\quad (l_i \\equiv \\neg m_j) \n",
    "\\;\\;\\;\\Rightarrow\\;\\;\\;\n",
    "(l_1 \\lor \\dots \\lor l_{i-1} \\lor l_{i+1} \\lor \\dots \\lor l_k \\lor m_1 \\lor \\dots \\lor m_{j-1} \\lor m_{j+1} \\lor \\dots \\lor m_n)\n",
    "$$\n",
    "\n",
    "\n",
    "### Hasil Resolusi\n",
    "\n",
    "Proses resolusi dijalankan berulang sampai salah satu kondisi berikut:\n",
    "\n",
    "1. Tidak ada klausa baru yang bisa ditambahkan → artinya $KB \\nvDash \\alpha$.  \n",
    "2. Ditemukan **klausa kosong** → artinya $KB \\vDash \\alpha$.  \n",
    "\n",
    "Klausa kosong setara dengan **False**, karena hanya bisa muncul dari resolusi dua klausa saling berlawanan, misalnya $P$ dan $\\neg P$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konversi Kalimat ke Bentuk Normal Konjungtif (CNF)\n",
    "\n",
    "Dalam pembuktian dengan **resolusi**, algoritma tidak bisa langsung menangani kalimat logika yang rumit.  \n",
    "Karena itu, kalimat yang mengandung **implikasi (→)** dan **bi-implikasi (↔)** harus disederhanakan dulu.\n",
    "\n",
    "👉 Fakta penting: **setiap kalimat logika proposisional setara dengan bentuk konjungsi dari klausa.**  \n",
    "Bentuk ini disebut **Conjunctive Normal Form (CNF)**, yaitu **konjungsi (AND)** dari beberapa **disjungsi (OR) literal**.\n",
    "\n",
    "Contoh CNF:\n",
    "\n",
    "$$\n",
    "(A \\lor B) \\land (\\neg B \\lor C \\lor \\neg D) \\land (D \\lor \\neg E)\n",
    "$$\n",
    "\n",
    "Bentuk ini sama seperti **Product of Sums (POS)** di elektronika digital.\n",
    "\n",
    "\n",
    "## Tahapan Konversi ke CNF\n",
    "\n",
    "### 1. Ubah Bi-Implikasi ke Implikasi\n",
    "$$\n",
    "\\alpha \\iff \\beta \\equiv (\\alpha \\implies \\beta) \\land (\\beta \\implies \\alpha)\n",
    "$$\n",
    "\n",
    "Jika bagian kanan berupa kalimat majemuk:\n",
    "$$\n",
    "\\alpha \\iff (\\beta \\lor \\gamma) \\equiv (\\alpha \\implies (\\beta \\lor \\gamma)) \\land ((\\beta \\lor \\gamma) \\implies \\alpha)\n",
    "$$\n",
    "\n",
    "\n",
    "### 2. Ubah Implikasi ke Bentuk Setara\n",
    "$$\n",
    "\\alpha \\implies \\beta \\equiv \\neg \\alpha \\lor \\beta\n",
    "$$\n",
    "\n",
    "\n",
    "### 3. Pindahkan Negasi ke Literal\n",
    "Negasi hanya boleh menempel pada proposisi atomik.  \n",
    "Gunakan **Hukum De Morgan**:\n",
    "\n",
    "$$\n",
    "\\neg(\\alpha \\land \\beta) \\equiv (\\neg \\alpha \\lor \\neg \\beta)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\neg(\\alpha \\lor \\beta) \\equiv (\\neg \\alpha \\land \\neg \\beta)\n",
    "$$\n",
    "\n",
    "\n",
    "### 4. Distribusikan Disjungsi terhadap Konjungsi\n",
    "Agar sesuai format CNF, lakukan distribusi:\n",
    "\n",
    "$$\n",
    "(\\alpha \\lor (\\beta \\land \\gamma)) \\equiv (\\alpha \\lor \\beta) \\land (\\alpha \\lor \\gamma)\n",
    "$$\n",
    "\n",
    "Bentuk akhir yang kita inginkan:\n",
    "\n",
    "$$\n",
    "(\\alpha_1 \\lor \\alpha_2 \\lor \\dots) \\land (\\beta_1 \\lor \\beta_2 \\lor \\dots) \\land (\\gamma_1 \\lor \\gamma_2 \\lor \\dots)\n",
    "$$\n",
    "\n",
    "\n",
    "## Inti Proses\n",
    "- CNF = **“AND of ORs”** (konjungsi dari disjungsi literal).  \n",
    "- Proses konversi = hilangkan ↔ dan →, dorong negasi ke literal, lalu distribusikan OR atas AND.  \n",
    "- Dengan CNF, kalimat siap dipakai dalam algoritma **resolusi**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def to_cnf(s):\n",
      "    \"\"\"\n",
      "    [Page 253]\n",
      "    Convert a propositional logical sentence to conjunctive normal form.\n",
      "    That is, to the form ((A | ~B | ...) & (B | C | ...) & ...)\n",
      "    >>> to_cnf('~(B | C)')\n",
      "    (~B & ~C)\n",
      "    \"\"\"\n",
      "    s = expr(s)\n",
      "    if isinstance(s, str):\n",
      "        s = expr(s)\n",
      "    s = eliminate_implications(s)  # Steps 1, 2 from p. 253\n",
      "    s = move_not_inwards(s)  # Step 3\n",
      "    return distribute_and_over_or(s)  # Step 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(to_cnf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fungsi `to_cnf`\n",
    "Untuk mengubah sebuah kalimat logika proposisional ke bentuk **Conjunctive Normal Form (CNF)**, kita gunakan fungsi `to_cnf`.  \n",
    "\n",
    "```python\n",
    "def to_cnf(s): \n",
    "    \"\"\"\n",
    "    [Page 253]\n",
    "    Convert a propositional logical sentence to conjunctive normal form.\n",
    "    That is, to the form ((A | ~B | ...) & (B | C | ...) & ...)\n",
    "    >>> to_cnf('~(B | C)')\n",
    "    (~B & ~C)\n",
    "    \"\"\"\n",
    "    s = expr(s)\n",
    "    if isinstance(s, str):\n",
    "        s = expr(s)\n",
    "    s = eliminate_implications(s)  # Steps 1, 2 from p. 253\n",
    "    s = move_not_inwards(s)        # Step 3\n",
    "    return distribute_and_over_or(s)  # Step 4\n",
    "```\n",
    "\n",
    "### Penjelasan Tahapan\n",
    "\n",
    "1. **`eliminate_implications(s)`**\n",
    "\n",
    "   * Menyelesaikan **Langkah 1 dan 2** dari proses konversi.\n",
    "   * Semua bi-implikasi (\\$\\alpha \\iff \\beta\\$) diubah menjadi dua implikasi.\n",
    "   * Semua implikasi (\\$\\alpha \\implies \\beta\\$) diubah menjadi bentuk setara (\\$\\neg \\alpha \\lor \\beta\\$).\n",
    "\n",
    "2. **`move_not_inwards(s)`**\n",
    "\n",
    "   * Menyelesaikan **Langkah 3**.\n",
    "   * Negasi digeser ke dalam agar hanya menempel pada literal, dengan bantuan hukum De Morgan.\n",
    "   * Contoh:\n",
    "\n",
    "     $$\n",
    "     \\neg (A \\lor B) \\equiv (\\neg A \\land \\neg B)\n",
    "     $$\n",
    "\n",
    "3. **`distribute_and_over_or(s)`**\n",
    "\n",
    "   * Menyelesaikan **Langkah 4**.\n",
    "   * Melakukan distribusi disjungsi terhadap konjungsi, sehingga hasil akhir berbentuk **konjungsi dari disjungsi literal**.\n",
    "   * Contoh:\n",
    "\n",
    "     $$\n",
    "     (A \\lor (B \\land C)) \\equiv (A \\lor B) \\land (A \\lor C)\n",
    "     $$\n",
    "\n",
    "\n",
    "### Intinya\n",
    "\n",
    "* Fungsi `to_cnf` = implementasi praktis dari 4 langkah konversi CNF.\n",
    "* Setiap kalimat proposisional bisa dipaksa ke CNF → siap dipakai untuk **algoritma resolusi**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def eliminate_implications(s):\n",
      "    \"\"\"Change implications into equivalent form with only &, |, and ~ as logical operators.\"\"\"\n",
      "    s = expr(s)\n",
      "    if not s.args or is_symbol(s.op):\n",
      "        return s  # Atoms are unchanged.\n",
      "    args = list(map(eliminate_implications, s.args))\n",
      "    a, b = args[0], args[-1]\n",
      "    if s.op == '==>':\n",
      "        return b | ~a\n",
      "    elif s.op == '<==':\n",
      "        return a | ~b\n",
      "    elif s.op == '<=>':\n",
      "        return (a | ~b) & (b | ~a)\n",
      "    elif s.op == '^':\n",
      "        assert len(args) == 2  # TODO: relax this restriction\n",
      "        return (a & ~b) | (~a & b)\n",
      "    else:\n",
      "        assert s.op in ('&', '|', '~')\n",
      "        return Expr(s.op, *args)\n",
      "\n",
      "def move_not_inwards(s):\n",
      "    \"\"\"Rewrite sentence s by moving negation sign inward.\n",
      "    >>> move_not_inwards(~(A | B))\n",
      "    (~A & ~B)\n",
      "    \"\"\"\n",
      "    s = expr(s)\n",
      "    if s.op == '~':\n",
      "        def NOT(b):\n",
      "            return move_not_inwards(~b)\n",
      "\n",
      "        a = s.args[0]\n",
      "        if a.op == '~':\n",
      "            return move_not_inwards(a.args[0])  # ~~A ==> A\n",
      "        if a.op == '&':\n",
      "            return associate('|', list(map(NOT, a.args)))\n",
      "        if a.op == '|':\n",
      "            return associate('&', list(map(NOT, a.args)))\n",
      "        return s\n",
      "    elif is_symbol(s.op) or not s.args:\n",
      "        return s\n",
      "    else:\n",
      "        return Expr(s.op, *list(map(move_not_inwards, s.args)))\n",
      "\n",
      "def distribute_and_over_or(s):\n",
      "    \"\"\"Given a sentence s consisting of conjunctions and disjunctions\n",
      "    of literals, return an equivalent sentence in CNF.\n",
      "    >>> distribute_and_over_or((A & B) | C)\n",
      "    ((A | C) & (B | C))\n",
      "    \"\"\"\n",
      "    s = expr(s)\n",
      "    if s.op == '|':\n",
      "        s = associate('|', s.args)\n",
      "        if s.op != '|':\n",
      "            return distribute_and_over_or(s)\n",
      "        if len(s.args) == 0:\n",
      "            return False\n",
      "        if len(s.args) == 1:\n",
      "            return distribute_and_over_or(s.args[0])\n",
      "        conj = first(arg for arg in s.args if arg.op == '&')\n",
      "        if not conj:\n",
      "            return s\n",
      "        others = [a for a in s.args if a is not conj]\n",
      "        rest = associate('|', others)\n",
      "        return associate('&', [distribute_and_over_or(c | rest)\n",
      "                               for c in conj.args])\n",
      "    elif s.op == '&':\n",
      "        return associate('&', list(map(distribute_and_over_or, s.args)))\n",
      "    else:\n",
      "        return s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(eliminate_implications))\n",
    "print(inspect.getsource(move_not_inwards))\n",
    "print(inspect.getsource(distribute_and_over_or))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Fungsi Pendukung `to_cnf`\n",
    "\n",
    "Agar `to_cnf` bekerja, ada tiga fungsi utama yang menjalankan proses sesuai 4 langkah konversi CNF:\n",
    "\n",
    "### 1. `eliminate_implications(s)`\n",
    "\n",
    "```python\n",
    "def eliminate_implications(s):\n",
    "    \"\"\"Change implications into equivalent form with only &, |, and ~ as logical operators.\"\"\"\n",
    "    s = expr(s)\n",
    "    if not s.args or is_symbol(s.op):\n",
    "        return s  # Atoms are unchanged.\n",
    "    args = list(map(eliminate_implications, s.args))\n",
    "    a, b = args[0], args[-1]\n",
    "    if s.op == '==>':\n",
    "        return b | ~a\n",
    "    elif s.op == '<==':\n",
    "        return a | ~b\n",
    "    elif s.op == '<=>':\n",
    "        return (a | ~b) & (b | ~a)\n",
    "    elif s.op == '^':\n",
    "        assert len(args) == 2\n",
    "        return (a & ~b) | (~a & b)\n",
    "    else:\n",
    "        assert s.op in ('&', '|', '~')\n",
    "        return Expr(s.op, *args)\n",
    "```\n",
    "\n",
    "**Fungsi:**\n",
    "\n",
    "* Menghilangkan semua **implikasi (⇒)** dan **bi-implikasi (⇔)**.\n",
    "* Hasil akhirnya hanya mengandung operator `&` (AND), `|` (OR), dan `~` (NOT).\n",
    "* Contoh:\n",
    "\n",
    "$$\n",
    "(P \\implies Q) \\equiv (\\neg P \\lor Q)\n",
    "$$\n",
    "\n",
    "$$\n",
    "(P \\iff Q) \\equiv (P \\implies Q) \\land (Q \\implies P)\n",
    "$$\n",
    "\n",
    "\n",
    "### 2. `move_not_inwards(s)`\n",
    "\n",
    "```python\n",
    "def move_not_inwards(s):\n",
    "    \"\"\"Rewrite sentence s by moving negation sign inward.\n",
    "    >>> move_not_inwards(~(A | B))\n",
    "    (~A & ~B)\n",
    "    \"\"\"\n",
    "    s = expr(s)\n",
    "    if s.op == '~':\n",
    "        def NOT(b):\n",
    "            return move_not_inwards(~b)\n",
    "\n",
    "        a = s.args[0]\n",
    "        if a.op == '~':\n",
    "            return move_not_inwards(a.args[0])  # ~~A ==> A\n",
    "        if a.op == '&':\n",
    "            return associate('|', list(map(NOT, a.args)))\n",
    "        if a.op == '|':\n",
    "            return associate('&', list(map(NOT, a.args)))\n",
    "        return s\n",
    "    elif is_symbol(s.op) or not s.args:\n",
    "        return s\n",
    "    else:\n",
    "        return Expr(s.op, *list(map(move_not_inwards, s.args)))\n",
    "```\n",
    "\n",
    "**Fungsi:**\n",
    "\n",
    "* Memindahkan **negasi** supaya hanya menempel pada literal (variabel atomik).\n",
    "* Menggunakan **Hukum De Morgan** dan penyederhanaan ganda:\n",
    "\n",
    "$$\n",
    "\\neg (A \\lor B) \\equiv (\\neg A \\land \\neg B)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\neg (A \\land B) \\equiv (\\neg A \\lor \\neg B)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\neg(\\neg A) \\equiv A\n",
    "$$\n",
    "\n",
    "\n",
    "### 3. `distribute_and_over_or(s)`\n",
    "\n",
    "```python\n",
    "def distribute_and_over_or(s):\n",
    "    \"\"\"Given a sentence s consisting of conjunctions and disjunctions\n",
    "    of literals, return an equivalent sentence in CNF.\n",
    "    >>> distribute_and_over_or((A & B) | C)\n",
    "    ((A | C) & (B | C))\n",
    "    \"\"\"\n",
    "    s = expr(s)\n",
    "    if s.op == '|':\n",
    "        s = associate('|', s.args)\n",
    "        if s.op != '|':\n",
    "            return distribute_and_over_or(s)\n",
    "        if len(s.args) == 0:\n",
    "            return False\n",
    "        if len(s.args) == 1:\n",
    "            return distribute_and_over_or(s.args[0])\n",
    "        conj = first(arg for arg in s.args if arg.op == '&')\n",
    "        if not conj:\n",
    "            return s\n",
    "        others = [a for a in s.args if a is not conj]\n",
    "        rest = associate('|', others)\n",
    "        return associate('&', [distribute_and_over_or(c | rest)\n",
    "                               for c in conj.args])\n",
    "    elif s.op == '&':\n",
    "        return associate('&', list(map(distribute_and_over_or, s.args)))\n",
    "    else:\n",
    "        return s\n",
    "```\n",
    "\n",
    "**Fungsi:**\n",
    "\n",
    "* Melakukan distribusi **OR terhadap AND**, supaya hasil akhir sesuai format CNF.\n",
    "* Contoh:\n",
    "\n",
    "$$\n",
    "(A \\land B) \\lor C \\equiv (A \\lor C) \\land (B \\lor C)\n",
    "$$\n",
    "\n",
    "\n",
    "## Alur Lengkap\n",
    "\n",
    "Jadi, `to_cnf` menjalankan ketiga fungsi ini berurutan:\n",
    "\n",
    "1. **Hilangkan implikasi** → `eliminate_implications(s)`\n",
    "2. **Pindahkan negasi** → `move_not_inwards(s)`\n",
    "3. **Distribusikan OR atas AND** → `distribute_and_over_or(s)`\n",
    "\n",
    "Hasil akhirnya selalu berbentuk:\n",
    "\n",
    "$$\n",
    "(\\alpha_1 \\lor \\alpha_2 \\lor \\dots) \\land (\\beta_1 \\lor \\beta_2 \\lor \\dots) \\land \\dots\n",
    "$$\n",
    "\n",
    "siap dipakai dalam algoritma **resolusi**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mari kita coba untuk konversi beberapa kalimat menjadi cnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((A | ~B) & (B | ~A))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, B, C, D = expr('A, B, C, D')\n",
    "to_cnf(A |'<=>'| B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((A | ~B | ~C) & (B | ~A) & (C | ~A))"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_cnf(A |'<=>'| (B & C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(A & (C | B) & (D | B))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_cnf(A & (B | (C & D)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((B | ~A | C | ~D) & (A | ~A | C | ~D) & (B | ~B | C | ~D) & (A | ~B | C | ~D))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_cnf((A |'<=>'| ~B) |'==>'| (C | ~D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementasi `pl_resolution`\n",
    "\n",
    "Setelah memahami fungsi `to_cnf`, kita bisa lihat bagaimana fungsi ini digunakan dalam algoritma **Proof by Resolution**.  \n",
    "Berikut kode dari fungsi `pl_resolution`:\n",
    "\n",
    "```python\n",
    "def pl_resolution(kb, alpha):\n",
    "    \"\"\"\n",
    "    [Figure 7.12]\n",
    "    Propositional-logic resolution: say if alpha follows from KB.\n",
    "    >>> pl_resolution(horn_clauses_KB, A)\n",
    "    True\n",
    "    \"\"\"\n",
    "    clauses = kb.clauses + conjuncts(to_cnf(~alpha))\n",
    "    new = set()\n",
    "    while True:\n",
    "        n = len(clauses)\n",
    "        pairs = [(clauses[i], clauses[j])\n",
    "                 for i in range(n) for j in range(i + 1, n)]\n",
    "        for (ci, cj) in pairs:\n",
    "            resolvents = pl_resolve(ci, cj)\n",
    "            if False in resolvents:\n",
    "                return True\n",
    "            new = new.union(set(resolvents))\n",
    "        if new.issubset(set(clauses)):\n",
    "            return False\n",
    "        for c in new:\n",
    "            if c not in clauses:\n",
    "                clauses.append(c)\n",
    "```\n",
    "\n",
    "### Alur Kerja `pl_resolution`\n",
    "\n",
    "1. **Persiapan klausa**\n",
    "\n",
    "   * Semua klausa dalam basis pengetahuan (`kb.clauses`) digabung dengan hasil konversi CNF dari negasi query `~alpha`.\n",
    "   * Hal ini sesuai prinsip resolusi: untuk membuktikan $\\text{KB} \\vDash \\alpha$, kita cek apakah $\\text{KB} \\land \\neg \\alpha$ tidak terpuaskan.\n",
    "\n",
    "2. **Inisialisasi**\n",
    "\n",
    "   * Variabel `new` dibuat sebagai himpunan kosong untuk menampung resolvent (klausa hasil resolusi).\n",
    "\n",
    "3. **Loop utama**\n",
    "\n",
    "   * Semua pasangan klausa dalam `clauses` diambil.\n",
    "   * Untuk setiap pasangan `(ci, cj)`, dijalankan fungsi `pl_resolve` untuk mencari resolvent.\n",
    "\n",
    "4. **Pengecekan kontradiksi**\n",
    "\n",
    "   * Jika ada resolvent yang menghasilkan `False` (klausa kosong), berarti kontradiksi ditemukan → $\\text{KB} \\vDash \\alpha$.\n",
    "   * Fungsi langsung mengembalikan `True`.\n",
    "\n",
    "5. **Update klausa**\n",
    "\n",
    "   * Semua resolvent baru dimasukkan ke dalam `new`.\n",
    "   * Jika `new` hanyalah subset dari klausa lama (tidak ada klausa baru yang muncul), artinya tidak ada resolusi lebih lanjut → algoritma berhenti dengan hasil `False` (tidak terbukti).\n",
    "   * Jika ada klausa baru, tambahkan ke `clauses` lalu ulangi proses.\n",
    "\n",
    "### Intuisi\n",
    "\n",
    "* **Kunci resolusi:** cari pasangan klausa yang punya literal saling berlawanan, lalu gabungkan sisanya.\n",
    "* **Tujuan:** terus menghasilkan klausa baru sampai:\n",
    "\n",
    "  1. Ketemu **klausa kosong** (kontradiksi → query terbukti).\n",
    "  2. Tidak ada klausa baru lagi (tidak terbukti).\n",
    "\n",
    "Dengan demikian, `pl_resolution` bekerja sebagai prosedur sistematis untuk mengecek entailment menggunakan prinsip **proof by contradiction** dengan bantuan konversi ke **CNF**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def pl_resolution(kb, alpha):\n",
      "    \"\"\"\n",
      "    [Figure 7.12]\n",
      "    Propositional-logic resolution: say if alpha follows from KB.\n",
      "    >>> pl_resolution(horn_clauses_KB, A)\n",
      "    True\n",
      "    \"\"\"\n",
      "    clauses = kb.clauses + conjuncts(to_cnf(~alpha))\n",
      "    new = set()\n",
      "    while True:\n",
      "        n = len(clauses)\n",
      "        pairs = [(clauses[i], clauses[j])\n",
      "                 for i in range(n) for j in range(i + 1, n)]\n",
      "        for (ci, cj) in pairs:\n",
      "            resolvents = pl_resolve(ci, cj)\n",
      "            if False in resolvents:\n",
      "                return True\n",
      "            new = new.union(set(resolvents))\n",
      "        if new.issubset(set(clauses)):\n",
      "            return False\n",
      "        for c in new:\n",
      "            if c not in clauses:\n",
      "                clauses.append(c)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(pl_resolution))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_resolution(wumpus_kb, ~P11), pl_resolution(wumpus_kb, P11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_resolution(wumpus_kb, ~P22), pl_resolution(wumpus_kb, P22)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hasil Uji `pl_resolution` pada Wumpus KB\n",
    "\n",
    "Kita menguji dua query berbeda pada basis pengetahuan Wumpus menggunakan fungsi `pl_resolution`.\n",
    "\n",
    "### 1. Query pada Kotak (1,1)\n",
    "\n",
    "```python\n",
    "pl_resolution(wumpus_kb, ~P11), pl_resolution(wumpus_kb, P11)\n",
    "# Hasil: (True, False)\n",
    "```\n",
    "\n",
    "**Penjelasan:**\n",
    "* `pl_resolution(wumpus_kb, ~P11) → True`\n",
    "  Artinya basis pengetahuan **dapat membuktikan bahwa di kotak (1,1) tidak ada pit**.\n",
    "  Hal ini sesuai aturan awal permainan Wumpus World: posisi awal pemain (1,1) selalu aman.\n",
    "\n",
    "* `pl_resolution(wumpus_kb, P11) → False`\n",
    "  Basis pengetahuan **tidak bisa membuktikan bahwa ada pit di (1,1)**, karena memang informasi dalam KB justru menyatakan sebaliknya.\n",
    "\n",
    "\n",
    "### 2. Query pada Kotak (2,2)\n",
    "\n",
    "```python\n",
    "pl_resolution(wumpus_kb, ~P22), pl_resolution(wumpus_kb, P22)\n",
    "# Hasil: (False, False)\n",
    "```\n",
    "\n",
    "**Penjelasan:**\n",
    "\n",
    "* `pl_resolution(wumpus_kb, ~P22) → False`\n",
    "  Basis pengetahuan **tidak bisa membuktikan bahwa (2,2) bebas pit**.\n",
    "  Informasi yang ada belum cukup untuk menyimpulkan aman atau tidak.\n",
    "\n",
    "* `pl_resolution(wumpus_kb, P22) → False`\n",
    "  Basis pengetahuan **juga tidak bisa membuktikan bahwa ada pit di (2,2)**.\n",
    "\n",
    "Dengan kata lain, posisi (2,2) masih **tidak diketahui statusnya** berdasarkan informasi yang tersedia.\n",
    "\n",
    "### Kesimpulan\n",
    "\n",
    "* Pada kotak awal (1,1), KB dengan jelas **meng-entail** bahwa tidak ada pit.\n",
    "* Pada kotak (2,2), KB belum punya informasi yang cukup, sehingga baik `P22` maupun `~P22` tidak bisa dibuktikan.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward dan Backward Chaining\n",
    "\n",
    "Sebelumnya kita sudah membahas dua algoritma untuk mengecek apakah sebuah kalimat di-*entail* oleh basis pengetahuan (`KB`).  \n",
    "Di sini kita perkenalkan **algoritma ketiga**, yaitu *forward chaining* dan *backward chaining*.  \n",
    "\n",
    "Perbedaan utamanya: tujuan sekarang adalah menentukan apakah basis pengetahuan yang hanya berisi **definite clause** dapat meng-entail sebuah simbol proposisi tunggal $q$ (query).  \n",
    "Namun, ada satu syarat penting: **basis pengetahuan hanya boleh berisi Horn Clauses**.\n",
    "\n",
    "#### Horn Clauses\n",
    "\n",
    "- **Horn Clause** adalah disjungsi (OR) dari beberapa literal dengan **paling banyak satu literal positif**.  \n",
    "- Jika sebuah Horn Clause memiliki tepat satu literal positif, maka ia disebut **Definite Clause**.  \n",
    "- Jika Horn Clause hanya berisi literal positif tunggal, ia disebut **Fact**.  \n",
    "\n",
    "Contoh Horn Clause:  \n",
    "\n",
    "$$\n",
    "\\neg a \\lor \\neg b \\lor \\neg c \\lor z\n",
    "$$\n",
    "\n",
    "Dengan menggunakan Hukum De Morgan, bentuk ini bisa ditulis ulang menjadi:  \n",
    "\n",
    "$$\n",
    "a \\land b \\land c \\;\\;\\implies\\;\\; z\n",
    "$$\n",
    "\n",
    "Artinya: jika $a$, $b$, dan $c$ semuanya benar, maka $z$ juga dapat disimpulkan benar.  \n",
    "Bentuk ini mirip dengan cara manusia memproses fakta dan pengetahuan untuk menghasilkan kesimpulan baru.\n",
    "\n",
    "#### Keunggulan Horn Clauses\n",
    "\n",
    "1. **Definite Clause dapat ditulis sebagai implikasi**  \n",
    "   - Premis (body) berupa konjungsi literal positif.  \n",
    "   - Kesimpulan (head) berupa satu literal positif.  \n",
    "   - Contoh:  \n",
    "\n",
    "     $$\n",
    "     a \\land b \\implies z\n",
    "     $$  \n",
    "\n",
    "   - Sebuah literal positif tunggal disebut **fact**.  \n",
    "   - Dengan bentuk seperti ini, aturan lebih mudah dipahami maupun diimplementasikan.\n",
    "\n",
    "2. **Bisa digunakan pada Forward dan Backward Chaining**  \n",
    "   - *Forward chaining* bekerja dengan menambahkan fakta baru secara progresif.  \n",
    "   - *Backward chaining* bekerja dengan menelusuri mundur dari query menuju fakta dasar.  \n",
    "   - Kedua algoritma ini berjalan efisien pada Horn Clauses karena bentuknya sudah sangat terstruktur.\n",
    "\n",
    "3. **Kompleksitas Linear**  \n",
    "   - Keputusan entailment dengan Horn Clauses hanya memerlukan traversal setiap klausa dalam basis pengetahuan **paling banyak sekali**.  \n",
    "   - Hal ini membuat proses inferensi jauh lebih efisien dibanding metode enumerasi atau resolusi umum.\n",
    "\n",
    "\n",
    "#### Implementasi di Kode\n",
    "\n",
    "Inferensi dengan *forward chaining* dapat diuji menggunakan fungsi:\n",
    "\n",
    "```python\n",
    "pl_fc_entails(KB, q)\n",
    "```\n",
    "\n",
    "Catatan penting:\n",
    "\n",
    "* Basis pengetahuan yang dipakai bukanlah instansi `KB` biasa.\n",
    "* `KB` di sini adalah objek dari kelas **`PropDefiniteKB`**, turunan dari `PropKB` yang dimodifikasi khusus untuk menyimpan **Definite Clause**.\n",
    "* Perbedaan utama ada pada metode bantu tambahan yang dapat mengembalikan daftar klausa dalam KB yang memiliki simbol tertentu di bagian premis.\n",
    "\n",
    "Dengan cara ini, forward chaining dapat lebih cepat menemukan aturan mana saja yang relevan ketika sebuah fakta baru muncul.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def clauses_with_premise(self, p):\n",
      "        \"\"\"Return a list of the clauses in KB that have p in their premise.\n",
      "        This could be cached away for O(1) speed, but we'll recompute it.\"\"\"\n",
      "        return [c for c in self.clauses if c.op == '==>' and p in conjuncts(c.args[0])]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(PropDefiniteKB.clauses_with_premise))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Fungsi `clauses_with_premise`\n",
    "\n",
    "```python\n",
    "psource(PropDefiniteKB.clauses_with_premise)\n",
    "def clauses_with_premise(self, p):\n",
    "    \"\"\"Return a list of the clauses in KB that have p in their premise.\n",
    "    This could be cached away for O(1) speed, but we'll recompute it.\"\"\"\n",
    "    return [c for c in self.clauses if c.op == '==>' and p in conjuncts(c.args[0])]\n",
    "```\n",
    "\n",
    "## Fungsi\n",
    "\n",
    "Digunakan untuk mengambil semua klausa dalam Knowledge Base (KB) yang memiliki simbol tertentu `p` pada bagian premis (bagian kiri implikasi).\n",
    "\n",
    "## Alur Kerja\n",
    "\n",
    "1. `self.clauses` → daftar semua klausa dalam basis pengetahuan.\n",
    "2. `c.op == '==>'` → hanya ambil klausa yang berupa implikasi (definite clause).\n",
    "3. `c.args[0]` → mengambil bagian premis dari klausa (bagian kiri sebelum `==>`).\n",
    "4. `conjuncts(c.args[0])` → memecah premis menjadi daftar konjungsi.\n",
    "5. `p in conjuncts(c.args[0])` → mengecek apakah simbol `p` ada di dalam premis.\n",
    "6. Hasil akhir berupa list semua klausa yang memenuhi kondisi di atas.\n",
    "\n",
    "## Intuisi\n",
    "\n",
    "Premis adalah syarat yang harus dipenuhi agar klausa berlaku.\n",
    "Fungsi ini digunakan untuk mencari aturan yang relevan dengan simbol tertentu di bagian premis.\n",
    "\n",
    "## Contoh\n",
    "\n",
    "Misalkan KB berisi klausa:\n",
    "\n",
    "1. `A & B ==> C`\n",
    "2. `D ==> E`\n",
    "3. `B ==> F`\n",
    "\n",
    "Jika dipanggil:\n",
    "\n",
    "```python\n",
    "clauses_with_premise(\"B\")\n",
    "```\n",
    "\n",
    "Maka hasilnya adalah:\n",
    "\n",
    "* `A & B ==> C`\n",
    "* `B ==> F`\n",
    "\n",
    "Kedua klausa tersebut dipilih karena premisnya mengandung `B`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now have a look at the `pl_fc_entails` algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def pl_fc_entails(kb, q):\n",
      "    \"\"\"\n",
      "    [Figure 7.15]\n",
      "    Use forward chaining to see if a PropDefiniteKB entails symbol q.\n",
      "    >>> pl_fc_entails(horn_clauses_KB, expr('Q'))\n",
      "    True\n",
      "    \"\"\"\n",
      "    count = {c: len(conjuncts(c.args[0])) for c in kb.clauses if c.op == '==>'}\n",
      "    inferred = defaultdict(bool)\n",
      "    agenda = [s for s in kb.clauses if is_prop_symbol(s.op)]\n",
      "    while agenda:\n",
      "        p = agenda.pop()\n",
      "        if p == q:\n",
      "            return True\n",
      "        if not inferred[p]:\n",
      "            inferred[p] = True\n",
      "            for c in kb.clauses_with_premise(p):\n",
      "                count[c] -= 1\n",
      "                if count[c] == 0:\n",
      "                    agenda.append(c.args[1])\n",
      "    return False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(pl_fc_entails))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function accepts a knowledge base `KB` (an instance of `PropDefiniteKB`) and a query `q` as inputs.\n",
    "<br>\n",
    "<br>\n",
    "`count` initially stores the number of symbols in the premise of each sentence in the knowledge base.\n",
    "<br>\n",
    "The `conjuncts` helper function separates a given sentence at conjunctions.\n",
    "<br>\n",
    "`inferred` is initialized as a *boolean* defaultdict. \n",
    "This will be used later to check if we have inferred all premises of each clause of the agenda.\n",
    "<br>\n",
    "`agenda` initially stores a list of clauses that the knowledge base knows to be true.\n",
    "The `is_prop_symbol` helper function checks if the given symbol is a valid propositional logic symbol.\n",
    "<br>\n",
    "<br>\n",
    "We now iterate through `agenda`, popping a symbol `p` on each iteration.\n",
    "If the query `q` is the same as `p`, we know that entailment holds.\n",
    "<br>\n",
    "The agenda is processed, reducing `count` by one for each implication with a premise `p`.\n",
    "A conclusion is added to the agenda when `count` reaches zero. This means we know all the premises of that particular implication to be true.\n",
    "<br>\n",
    "`clauses_with_premise` is a helpful method of the `PropKB` class.\n",
    "It returns a list of clauses in the knowledge base that have `p` in their premise.\n",
    "<br>\n",
    "<br>\n",
    "Now that we have an idea of how this function works, let's see a few examples of its usage, but we first need to define our knowledge base. We assume we know the following clauses to be true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clauses = ['(B & F)==>E', \n",
    "           '(A & E & F)==>G', \n",
    "           '(B & C)==>F', \n",
    "           '(A & B)==>D', \n",
    "           '(E & F)==>H', \n",
    "           '(H & I)==>J',\n",
    "           'A', \n",
    "           'B', \n",
    "           'C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now `tell` this information to our knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "definite_clauses_KB = PropDefiniteKB()\n",
    "for clause in clauses:\n",
    "    definite_clauses_KB.tell(expr(clause))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check if our knowledge base entails the following queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_fc_entails(definite_clauses_KB, expr('G'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_fc_entails(definite_clauses_KB, expr('H'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_fc_entails(definite_clauses_KB, expr('I'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_fc_entails(definite_clauses_KB, expr('J'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First-Order Logic Knowledge Bases: `FolKB`\n",
    "\n",
    "The class `FolKB` can be used to represent a knowledge base of First-order logic sentences. You would initialize and use it the same way as you would for `PropKB` except that the clauses are first-order definite clauses. We will see how to write such clauses to create a database and query them in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criminal KB\n",
    "In this section we create a `FolKB` based on the following paragraph.<br/>\n",
    "<em>The law says that it is a crime for an American to sell weapons to hostile nations. The country Nono, an enemy of America, has some missiles, and all of its missiles were sold to it by Colonel West, who is American.</em><br/>\n",
    "The first step is to extract the facts and convert them into first-order definite clauses. Extracting the facts from data alone is a challenging task. Fortunately, we have a small paragraph and can do extraction and conversion manually. We'll store the clauses in list aptly named `clauses`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clauses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>“... it is a crime for an American to sell weapons to hostile nations”</em><br/>\n",
    "The keywords to look for here are 'crime', 'American', 'sell', 'weapon' and 'hostile'. We use predicate symbols to make meaning of them.\n",
    "\n",
    "* `Criminal(x)`: `x` is a criminal\n",
    "* `American(x)`: `x` is an American\n",
    "* `Sells(x ,y, z)`: `x` sells `y` to `z`\n",
    "* `Weapon(x)`: `x` is a weapon\n",
    "* `Hostile(x)`: `x` is a hostile nation\n",
    "\n",
    "Let us now combine them with appropriate variable naming to depict the meaning of the sentence. The criminal `x` is also the American `x` who sells weapon `y` to `z`, which is a hostile nation.\n",
    "\n",
    "$\\text{American}(x) \\land \\text{Weapon}(y) \\land \\text{Sells}(x, y, z) \\land \\text{Hostile}(z) \\implies \\text{Criminal} (x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clauses.append(expr(\"(American(x) & Weapon(y) & Sells(x, y, z) & Hostile(z)) ==> Criminal(x)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>\"The country Nono, an enemy of America\"</em><br/>\n",
    "We now know that Nono is an enemy of America. We represent these nations using the constant symbols `Nono` and `America`. the enemy relation is show using the predicate symbol `Enemy`.\n",
    "\n",
    "$\\text{Enemy}(\\text{Nono}, \\text{America})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clauses.append(expr(\"Enemy(Nono, America)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>\"Nono ... has some missiles\"</em><br/>\n",
    "This states the existence of some missile which is owned by Nono. $\\exists x \\text{Owns}(\\text{Nono}, x) \\land \\text{Missile}(x)$. We invoke existential instantiation to introduce a new constant `M1` which is the missile owned by Nono.\n",
    "\n",
    "$\\text{Owns}(\\text{Nono}, \\text{M1}), \\text{Missile}(\\text{M1})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clauses.append(expr(\"Owns(Nono, M1)\"))\n",
    "clauses.append(expr(\"Missile(M1)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<em>\"All of its missiles were sold to it by Colonel West\"</em><br/>\n",
    "If Nono owns something and it classifies as a missile, then it was sold to Nono by West.\n",
    "\n",
    "$\\text{Missile}(x) \\land \\text{Owns}(\\text{Nono}, x) \\implies \\text{Sells}(\\text{West}, x, \\text{Nono})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clauses.append(expr(\"(Missile(x) & Owns(Nono, x)) ==> Sells(West, x, Nono)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>\"West, who is American\"</em><br/>\n",
    "West is an American.\n",
    "\n",
    "$\\text{American}(\\text{West})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clauses.append(expr(\"American(West)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also know, from our understanding of language, that missiles are weapons and that an enemy of America counts as “hostile”.\n",
    "\n",
    "$\\text{Missile}(x) \\implies \\text{Weapon}(x), \\text{Enemy}(x, \\text{America}) \\implies \\text{Hostile}(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clauses.append(expr(\"Missile(x) ==> Weapon(x)\"))\n",
    "clauses.append(expr(\"Enemy(x, America) ==> Hostile(x)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have converted the information into first-order definite clauses we can create our first-order logic knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crime_kb = FolKB(clauses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `subst` helper function substitutes variables with given values in first-order logic statements.\n",
    "This will be useful in later algorithms.\n",
    "It's implementation is quite simple and self-explanatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def subst(s, x):\n",
      "    \"\"\"Substitute the substitution s into the expression x.\n",
      "    >>> subst({x: 42, y:0}, F(x) + y)\n",
      "    (F(42) + 0)\n",
      "    \"\"\"\n",
      "    if isinstance(x, list):\n",
      "        return [subst(s, xi) for xi in x]\n",
      "    elif isinstance(x, tuple):\n",
      "        return tuple([subst(s, xi) for xi in x])\n",
      "    elif not isinstance(x, Expr):\n",
      "        return x\n",
      "    elif is_var_symbol(x.op):\n",
      "        return s.get(x, x)\n",
      "    else:\n",
      "        return Expr(x.op, *[subst(s, arg) for arg in x.args])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(subst))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of how `subst` can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Owns(Nono, M1)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subst({x: expr('Nono'), y: expr('M1')}, expr('Owns(x, y)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference in First-Order Logic\n",
    "In this section we look at a forward chaining and a backward chaining algorithm for `FolKB`. Both aforementioned algorithms rely on a process called <strong>unification</strong>, a key component of all first-order inference algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unification\n",
    "We sometimes require finding substitutions that make different logical expressions look identical. This process, called unification, is done by the `unify` algorithm. It takes as input two sentences and returns a <em>unifier</em> for them if one exists. A unifier is a dictionary which stores the substitutions required to make the two sentences identical. It does so by recursively unifying the components of a sentence, where the unification of a variable symbol `var` with a constant symbol `Const` is the mapping `{var: Const}`. Let's look at a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{x: 3}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unify(expr('x'), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{x: B}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unify(expr('A(x)'), expr('A(B)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{x: Bella, y: Dobby}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unify(expr('Cat(x) & Dog(Dobby)'), expr('Cat(Bella) & Dog(y)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cases where there is no possible substitution that unifies the two sentences the function return `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(unify(expr('Cat(x)'), expr('Dog(Dobby)')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to take care we do not unintentionally use the same variable name. Unify treats them as a single variable which prevents it from taking multiple value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(unify(expr('Cat(x) & Dog(Dobby)'), expr('Cat(Bella) & Dog(x)')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Chaining Algorithm\n",
    "We consider the simple forward-chaining algorithm presented in <em>Figure 9.3</em>. We look at each rule in the knowledge base and see if the premises can be satisfied. This is done by finding a substitution which unifies each of the premise with a clause in the `KB`. If we are able to unify the premises, the conclusion (with the corresponding substitution) is added to the `KB`. This inferencing process is repeated until either the query can be answered or till no new sentences can be added. We test if the newly added clause unifies with the query in which case the substitution yielded by `unify` is an answer to the query. If we run out of sentences to infer, this means the query was a failure.\n",
    "\n",
    "The function `fol_fc_ask` is a generator which yields all substitutions which validate the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def fol_fc_ask(kb, alpha):\n",
      "    \"\"\"\n",
      "    [Figure 9.3]\n",
      "    A simple forward-chaining algorithm.\n",
      "    \"\"\"\n",
      "    # TODO: improve efficiency\n",
      "    kb_consts = list({c for clause in kb.clauses for c in constant_symbols(clause)})\n",
      "\n",
      "    def enum_subst(p):\n",
      "        query_vars = list({v for clause in p for v in variables(clause)})\n",
      "        for assignment_list in itertools.product(kb_consts, repeat=len(query_vars)):\n",
      "            theta = {x: y for x, y in zip(query_vars, assignment_list)}\n",
      "            yield theta\n",
      "\n",
      "    # check if we can answer without new inferences\n",
      "    for q in kb.clauses:\n",
      "        phi = unify_mm(q, alpha)\n",
      "        if phi is not None:\n",
      "            yield phi\n",
      "\n",
      "    while True:\n",
      "        new = []\n",
      "        for rule in kb.clauses:\n",
      "            p, q = parse_definite_clause(rule)\n",
      "            for theta in enum_subst(p):\n",
      "                if set(subst(theta, p)).issubset(set(kb.clauses)):\n",
      "                    q_ = subst(theta, q)\n",
      "                    if all([unify_mm(x, q_) is None for x in kb.clauses + new]):\n",
      "                        new.append(q_)\n",
      "                        phi = unify_mm(q_, alpha)\n",
      "                        if phi is not None:\n",
      "                            yield phi\n",
      "        if not new:\n",
      "            break\n",
      "        for clause in new:\n",
      "            kb.tell(clause)\n",
      "    return None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(fol_fc_ask))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out all the hostile nations. Note that we only told the `KB` that Nono was an enemy of America, not that it was hostile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{x: Nono}]\n"
     ]
    }
   ],
   "source": [
    "answer = fol_fc_ask(crime_kb, expr('Hostile(x)'))\n",
    "print(list(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generator returned a single substitution which says that Nono is a hostile nation. See how after adding another enemy nation the generator returns two substitutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{x: Nono}, {x: JaJa}]\n"
     ]
    }
   ],
   "source": [
    "crime_kb.tell(expr('Enemy(JaJa, America)'))\n",
    "answer = fol_fc_ask(crime_kb, expr('Hostile(x)'))\n",
    "print(list(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><em>Note</em>:</strong> `fol_fc_ask` makes changes to the `KB` by adding sentences to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Chaining Algorithm\n",
    "This algorithm works backward from the goal, chaining through rules to find known facts that support the proof. Suppose `goal` is the query we want to find the substitution for. We find rules of the form $\\text{lhs} \\implies \\text{goal}$ in the `KB` and try to prove `lhs`. There may be multiple clauses in the `KB` which give multiple `lhs`. It is sufficient to prove only one of these. But to prove a `lhs` all the conjuncts in the `lhs` of the clause must be proved. This makes it similar to <em>And/Or</em> search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OR\n",
    "The <em>OR</em> part of the algorithm comes from our choice to select any clause of the form $\\text{lhs} \\implies \\text{goal}$. Looking at all rules's `lhs` whose `rhs` unify with the `goal`, we yield a substitution which proves all the conjuncts in the `lhs`. We use `parse_definite_clause` to attain `lhs` and `rhs` from a clause of the form $\\text{lhs} \\implies \\text{rhs}$. For atomic facts the `lhs` is an empty list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def fol_bc_or(kb, goal, theta):\n",
      "    for rule in kb.fetch_rules_for_goal(goal):\n",
      "        lhs, rhs = parse_definite_clause(standardize_variables(rule))\n",
      "        for theta1 in fol_bc_and(kb, lhs, unify_mm(rhs, goal, theta)):\n",
      "            yield theta1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(fol_bc_or))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AND\n",
    "The <em>AND</em> corresponds to proving all the conjuncts in the `lhs`. We need to find a substitution which proves each <em>and</em> every clause in the list of conjuncts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def fol_bc_and(kb, goals, theta):\n",
      "    if theta is None:\n",
      "        pass\n",
      "    elif not goals:\n",
      "        yield theta\n",
      "    else:\n",
      "        first, rest = goals[0], goals[1:]\n",
      "        for theta1 in fol_bc_or(kb, subst(theta, first), theta):\n",
      "            for theta2 in fol_bc_and(kb, rest, theta1):\n",
      "                yield theta2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(fol_bc_and))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the main function `fl_bc_ask` calls `fol_bc_or` with substitution initialized as empty. The `ask` method of `FolKB` uses `fol_bc_ask` and fetches the first substitution returned by the generator to answer query. Let's query the knowledge base we created from `clauses` to find hostile nations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rebuild KB because running fol_fc_ask would add new facts to the KB\n",
    "crime_kb = FolKB(clauses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{v_194: Nono, x: Nono}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crime_kb.ask(expr('Hostile(x)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice some new variables in the substitution. They are introduced to standardize the variable names to prevent naming problems as discussed in the [Unification section](#Unification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: The Implementation of `|'==>'|`\n",
    "\n",
    "Consider the `Expr` formed by this syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(P ==> ~Q)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P |'==>'| ~Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the funny `|'==>'|` syntax? The trick is that \"`|`\" is just the regular Python or-operator, and so is exactly equivalent to this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(P ==> ~Q)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(P | '==>') | ~Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, there are two applications of or-operators. Here's the first one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PartialExpr('==>', P)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P | '==>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is going on here is that the `__or__` method of `Expr` serves a dual purpose. If the right-hand-side is another `Expr` (or a number), then the result is an `Expr`, as in `(P | Q)`. But if the right-hand-side is a string, then the string is taken to be an operator, and we create a node in the abstract syntax tree corresponding to a partially-filled  `Expr`, one where we know the left-hand-side is `P` and the operator is `==>`, but we don't yet know the right-hand-side.\n",
    "\n",
    "The `PartialExpr` class has an `__or__` method that says to create an `Expr` node with the right-hand-side filled in. Here we can see the combination of the `PartialExpr` with `Q` to create a complete `Expr`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(P ==> ~Q)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial = PartialExpr('==>', P) \n",
    "partial | ~Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This  [trick](http://code.activestate.com/recipes/384122-infix-operators/) is due to [Ferdinand Jamitzky](http://code.activestate.com/recipes/users/98863/), with a modification by [C. G. Vedant](https://github.com/Chipe1),\n",
    "who suggested using a string inside the or-bars.\n",
    "\n",
    "## Appendix: The Implementation of `expr`\n",
    "\n",
    "How does `expr` parse a string into an `Expr`? It turns out there are two tricks (besides the Jamitzky/Vedant trick):\n",
    "\n",
    "1. We do a string substitution, replacing \"`==>`\" with \"`|'==>'|`\" (and likewise for other operators).\n",
    "2. We `eval` the resulting string in an environment in which every identifier\n",
    "is bound to a symbol with that identifier as the `op`.\n",
    "\n",
    "In other words,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(~(P & Q) ==> (~P | ~Q))"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr('~(P & Q)  ==>  (~P | ~Q)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is equivalent to doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(~(P & Q) ==> (~P | ~Q))"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P, Q = symbols('P, Q')\n",
    "~(P & Q)  |'==>'|  (~P | ~Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to beware of: this puts `==>` at the same precedence level as `\"|\"`, which is not quite right. For example, we get this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((P & Q) ==> P) | Q)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P & Q  |'==>'|  P | Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is probably not what we meant; when in doubt, put in extra parens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((P & Q) ==> (P | Q))"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(P & Q)  |'==>'|  (P | Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script type=\"text/javascript\" src=\"./js/canvas.js\"></script>\n",
       "<div>\n",
       "<canvas id=\"canvas_bc_ask\" width=\"800\" height=\"600\" style=\"background:rgba(158, 167, 184, 0.2);\" onclick='click_callback(this, event, \"canvas_bc_ask\")'></canvas>\n",
       "</div>\n",
       "\n",
       "<script> var canvas_bc_ask_canvas_object = new Canvas(\"canvas_bc_ask\");</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>\n",
       "canvas_bc_ask_canvas_object.clear();\n",
       "canvas_bc_ask_canvas_object.strokeWidth(3);\n",
       "canvas_bc_ask_canvas_object.stroke(0, 0, 0);\n",
       "canvas_bc_ask_canvas_object.font(\"12px Arial\");\n",
       "canvas_bc_ask_canvas_object.fill(200, 200, 200);\n",
       "canvas_bc_ask_canvas_object.rect(340, 85, 120, 30);\n",
       "canvas_bc_ask_canvas_object.line(340, 85, 460, 85);\n",
       "canvas_bc_ask_canvas_object.line(340, 85, 340, 115);\n",
       "canvas_bc_ask_canvas_object.line(460, 85, 460, 115);\n",
       "canvas_bc_ask_canvas_object.line(340, 115, 460, 115);\n",
       "canvas_bc_ask_canvas_object.fill(0, 0, 0);\n",
       "canvas_bc_ask_canvas_object.fill_text(\"Criminal(West)\", 348, 109);\n",
       "canvas_bc_ask_canvas_object.fill(200, 200, 200);\n",
       "canvas_bc_ask_canvas_object.rect(55, 255, 120, 30);\n",
       "canvas_bc_ask_canvas_object.line(55, 255, 175, 255);\n",
       "canvas_bc_ask_canvas_object.line(55, 255, 55, 285);\n",
       "canvas_bc_ask_canvas_object.line(175, 255, 175, 285);\n",
       "canvas_bc_ask_canvas_object.line(55, 285, 175, 285);\n",
       "canvas_bc_ask_canvas_object.fill(0, 0, 0);\n",
       "canvas_bc_ask_canvas_object.fill_text(\"American(West)\", 63, 279);\n",
       "canvas_bc_ask_canvas_object.fill(200, 200, 200);\n",
       "canvas_bc_ask_canvas_object.rect(245, 255, 120, 30);\n",
       "canvas_bc_ask_canvas_object.line(245, 255, 365, 255);\n",
       "canvas_bc_ask_canvas_object.line(245, 255, 245, 285);\n",
       "canvas_bc_ask_canvas_object.line(365, 255, 365, 285);\n",
       "canvas_bc_ask_canvas_object.line(245, 285, 365, 285);\n",
       "canvas_bc_ask_canvas_object.fill(0, 0, 0);\n",
       "canvas_bc_ask_canvas_object.fill_text(\"Weapon(M1)\", 253, 279);\n",
       "canvas_bc_ask_canvas_object.fill(200, 200, 200);\n",
       "canvas_bc_ask_canvas_object.rect(435, 255, 120, 30);\n",
       "canvas_bc_ask_canvas_object.line(435, 255, 555, 255);\n",
       "canvas_bc_ask_canvas_object.line(435, 255, 435, 285);\n",
       "canvas_bc_ask_canvas_object.line(555, 255, 555, 285);\n",
       "canvas_bc_ask_canvas_object.line(435, 285, 555, 285);\n",
       "canvas_bc_ask_canvas_object.fill(0, 0, 0);\n",
       "canvas_bc_ask_canvas_object.fill_text(\"Sells(West, M1, Nono)\", 443, 279);\n",
       "canvas_bc_ask_canvas_object.fill(200, 200, 200);\n",
       "canvas_bc_ask_canvas_object.rect(625, 255, 120, 30);\n",
       "canvas_bc_ask_canvas_object.line(625, 255, 745, 255);\n",
       "canvas_bc_ask_canvas_object.line(625, 255, 625, 285);\n",
       "canvas_bc_ask_canvas_object.line(745, 255, 745, 285);\n",
       "canvas_bc_ask_canvas_object.line(625, 285, 745, 285);\n",
       "canvas_bc_ask_canvas_object.fill(0, 0, 0);\n",
       "canvas_bc_ask_canvas_object.fill_text(\"Hostile(Nono)\", 633, 279);\n",
       "canvas_bc_ask_canvas_object.fill(200, 200, 200);\n",
       "canvas_bc_ask_canvas_object.rect(55, 425, 120, 30);\n",
       "canvas_bc_ask_canvas_object.line(55, 425, 175, 425);\n",
       "canvas_bc_ask_canvas_object.line(55, 425, 55, 455);\n",
       "canvas_bc_ask_canvas_object.line(175, 425, 175, 455);\n",
       "canvas_bc_ask_canvas_object.line(55, 455, 175, 455);\n",
       "canvas_bc_ask_canvas_object.fill(0, 0, 0);\n",
       "canvas_bc_ask_canvas_object.fill_text(\"Missile(M1)\", 63, 449);\n",
       "canvas_bc_ask_canvas_object.fill(200, 200, 200);\n",
       "canvas_bc_ask_canvas_object.rect(245, 425, 120, 30);\n",
       "canvas_bc_ask_canvas_object.line(245, 425, 365, 425);\n",
       "canvas_bc_ask_canvas_object.line(245, 425, 245, 455);\n",
       "canvas_bc_ask_canvas_object.line(365, 425, 365, 455);\n",
       "canvas_bc_ask_canvas_object.line(245, 455, 365, 455);\n",
       "canvas_bc_ask_canvas_object.fill(0, 0, 0);\n",
       "canvas_bc_ask_canvas_object.fill_text(\"Missile(M1)\", 253, 449);\n",
       "canvas_bc_ask_canvas_object.fill(200, 200, 200);\n",
       "canvas_bc_ask_canvas_object.rect(435, 425, 120, 30);\n",
       "canvas_bc_ask_canvas_object.line(435, 425, 555, 425);\n",
       "canvas_bc_ask_canvas_object.line(435, 425, 435, 455);\n",
       "canvas_bc_ask_canvas_object.line(555, 425, 555, 455);\n",
       "canvas_bc_ask_canvas_object.line(435, 455, 555, 455);\n",
       "canvas_bc_ask_canvas_object.fill(0, 0, 0);\n",
       "canvas_bc_ask_canvas_object.fill_text(\"Owns(Nono, M1)\", 443, 449);\n",
       "canvas_bc_ask_canvas_object.fill(200, 200, 200);\n",
       "canvas_bc_ask_canvas_object.rect(625, 425, 120, 30);\n",
       "canvas_bc_ask_canvas_object.line(625, 425, 745, 425);\n",
       "canvas_bc_ask_canvas_object.line(625, 425, 625, 455);\n",
       "canvas_bc_ask_canvas_object.line(745, 425, 745, 455);\n",
       "canvas_bc_ask_canvas_object.line(625, 455, 745, 455);\n",
       "canvas_bc_ask_canvas_object.fill(0, 0, 0);\n",
       "canvas_bc_ask_canvas_object.fill_text(\"Enemy(Nono, America)\", 633, 449);\n",
       "canvas_bc_ask_canvas_object.line(685, 285, 685, 425);\n",
       "canvas_bc_ask_canvas_object.line(400, 115, 685, 255);\n",
       "canvas_bc_ask_canvas_object.line(305, 285, 115, 425);\n",
       "canvas_bc_ask_canvas_object.line(495, 285, 305, 425);\n",
       "canvas_bc_ask_canvas_object.line(400, 115, 115, 255);\n",
       "canvas_bc_ask_canvas_object.line(495, 285, 495, 425);\n",
       "canvas_bc_ask_canvas_object.line(400, 115, 305, 255);\n",
       "canvas_bc_ask_canvas_object.line(400, 115, 495, 255);\n",
       "canvas_bc_ask_canvas_object.fill(255, 255, 255);\n",
       "canvas_bc_ask_canvas_object.rect(0, 540, 800, 60);\n",
       "canvas_bc_ask_canvas_object.strokeWidth(5);\n",
       "canvas_bc_ask_canvas_object.stroke(0, 0, 0);\n",
       "canvas_bc_ask_canvas_object.line(0, 540, 800, 540);\n",
       "canvas_bc_ask_canvas_object.font(\"22px Arial\");\n",
       "canvas_bc_ask_canvas_object.fill(0, 0, 0);\n",
       "canvas_bc_ask_canvas_object.fill_text(\"Click for text\", 20, 585);\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from notebook import Canvas_fol_bc_ask\n",
    "canvas_bc_ask = Canvas_fol_bc_ask('canvas_bc_ask', crime_kb, expr('Criminal(x)'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CI (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
