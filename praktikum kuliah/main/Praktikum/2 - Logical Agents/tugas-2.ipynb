{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Laporan Praktikum 2 – Kecerdasan Komputasional  \n",
    "## Proof by Resolution, Forward & Backward Chaining, dan First-Order Logic  \n",
    "\n",
    "\n",
    "### Identitas Mahasiswa\n",
    "- Nama  : Wayan Raditya Putra  \n",
    "- NRP   : 5054241029  \n",
    "- Program Studi : Rekayasa Kecerdasan Artifisial\n",
    "- Angkatan : 2024  \n",
    "\n",
    "\n",
    "### Tujuan Praktikum\n",
    "Praktikum ini bertujuan untuk:  \n",
    "1. Memahami konsep dasar Proof by Resolution sebagai teknik inferensi dalam logika.  \n",
    "2. Mempelajari mekanisme Forward Chaining dan Backward Chaining untuk penalaran berbasis aturan.  \n",
    "3. Mengenal representasi First-Order Logic (FOL) dan bagaimana FOL digunakan dalam basis pengetahuan.  \n",
    "4. Mengimplementasikan berbagai teknik inferensi untuk menyelesaikan permasalahan berbasis logika komputasional.  \n",
    "\n",
    "\n",
    "### Deskripsi Singkat\n",
    "Pada praktikum kedua ini, mahasiswa diminta untuk:  \n",
    "- Menyusun representasi basis pengetahuan dalam bentuk proposisi maupun logika orde pertama.  \n",
    "- Menerapkan teknik inferensi seperti resolution, forward chaining, backward chaining.  \n",
    "- Melakukan percobaan terhadap kasus sederhana untuk melihat bagaimana sistem inferensi menghasilkan kesimpulan dari basis pengetahuan.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalasi dan Import Library\n",
    "\n",
    "**Tujuan:**  \n",
    "Menyiapkan library dan modul yang diperlukan sebelum menjalankan praktikum. Pada tahap ini dilakukan instalasi paket eksternal serta import fungsi-fungsi yang sudah tersedia di file pendukung.\n",
    "\n",
    "```python\n",
    "%pip install ipythonblocks\n",
    "%pip install qpsolvers\n",
    "\n",
    "from utils import *\n",
    "from logic import *\n",
    "from notebook import psource\n",
    "````\n",
    "**Penjelasan:**\n",
    "\n",
    "* `%pip install ipythonblocks` → menginstal library **ipythonblocks** yang digunakan untuk menampilkan blok warna pada notebook.\n",
    "* `%pip install qpsolvers` → menginstal library **qpsolvers** yang digunakan untuk menyelesaikan masalah Quadratic Programming.\n",
    "* `from utils import *` → mengimpor seluruh fungsi dari file `utils.py` yang berisi kumpulan fungsi bantu.\n",
    "* `from logic import *` → mengimpor seluruh fungsi dari file `logic.py` yang berisi implementasi logika proposisional dan inference.\n",
    "* `from notebook import psource` → mengimpor fungsi `psource` dari `notebook.py`, yang digunakan untuk menampilkan source code suatu fungsi langsung di notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipythonblocks in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (1.9.1)\n",
      "Requirement already satisfied: ipython>=4.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipythonblocks) (9.5.0)\n",
      "Requirement already satisfied: notebook>=4.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipythonblocks) (7.4.5)\n",
      "Requirement already satisfied: requests>=1.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipythonblocks) (2.32.5)\n",
      "Requirement already satisfied: colorama in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (0.4.6)\n",
      "Requirement already satisfied: decorator in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (2.19.2)\n",
      "Requirement already satisfied: stack_data in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=4.0->ipythonblocks) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jedi>=0.16->ipython>=4.0->ipythonblocks) (0.8.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from notebook>=4.0->ipythonblocks) (2.17.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from notebook>=4.0->ipythonblocks) (2.27.3)\n",
      "Requirement already satisfied: jupyterlab<4.5,>=4.4.5 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from notebook>=4.0->ipythonblocks) (4.4.7)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from notebook>=4.0->ipythonblocks) (0.2.4)\n",
      "Requirement already satisfied: tornado>=6.2.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from notebook>=4.0->ipythonblocks) (6.5.2)\n",
      "Requirement already satisfied: anyio>=3.1.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (4.10.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (25.1.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (3.1.6)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (5.8.1)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (5.10.4)\n",
      "Requirement already satisfied: packaging>=22.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (25.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.22.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (3.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (27.0.2)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (2.0.5)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (0.28.1)\n",
      "Requirement already satisfied: ipykernel!=6.30.0,>=6.5.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (6.30.1)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (2.3.0)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (80.9.0)\n",
      "Requirement already satisfied: certifi in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (1.0.9)\n",
      "Requirement already satisfied: idna in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (0.16.0)\n",
      "Requirement already satisfied: babel>=2.10 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.0->ipythonblocks) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.0->ipythonblocks) (0.12.1)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.0->ipythonblocks) (4.25.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (4.15.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (25.1.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (1.8.16)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.7 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (7.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jinja2>=3.0.3->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.0->ipythonblocks) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.0->ipythonblocks) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.0->ipythonblocks) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.0->ipythonblocks) (0.27.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (4.4.0)\n",
      "Requirement already satisfied: pywin32>=300 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (311)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (3.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.1.1)\n",
      "Requirement already satisfied: fqdn in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.5.1)\n",
      "Requirement already satisfied: isoduration in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.1.0)\n",
      "Requirement already satisfied: uri-template in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (24.11.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (4.13.5)\n",
      "Requirement already satisfied: bleach!=5.0.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.5.1)\n",
      "Requirement already satisfied: webencodings in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (2.21.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from requests>=1.0->ipythonblocks) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from requests>=1.0->ipythonblocks) (2.5.0)\n",
      "Requirement already satisfied: lark>=1.2.2 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.2.2)\n",
      "Requirement already satisfied: cffi>=1.0.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.17.1)\n",
      "Requirement already satisfied: pycparser in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (2.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (2.8)\n",
      "Requirement already satisfied: arrow>=0.15.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (2.9.0.20250822)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from stack_data->ipython>=4.0->ipythonblocks) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from stack_data->ipython>=4.0->ipythonblocks) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from stack_data->ipython>=4.0->ipythonblocks) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: qpsolvers in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (4.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from qpsolvers) (2.3.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from qpsolvers) (1.16.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipythonblocks\n",
    "%pip install qpsolvers\n",
    "from utils import *\n",
    "from logic import *\n",
    "from notebook import psource\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferensi pada Basis Pengetahuan Proposisional\n",
    "\n",
    "**Tujuan:**  \n",
    "Pada bagian ini kita akan mempelajari dua teknik utama yang digunakan untuk memeriksa apakah suatu kalimat (sentence) dapat di-*entail* oleh sebuah basis pengetahuan (`KB`).  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof by Resolution\n",
    "\n",
    "Tujuan kita adalah memeriksa apakah $KB \\vDash \\alpha$, yaitu apakah $KB \\implies \\alpha$ bernilai benar di setiap model.  \n",
    "\n",
    "Contoh: kita ingin memeriksa apakah $P \\implies Q$ valid.  \n",
    "Untuk itu kita periksa keterpuasan dari $\\neg (P \\implies Q)$, yang bisa ditulis ulang menjadi:  \n",
    "\n",
    "$$\n",
    "P \\land \\neg Q\n",
    "$$\n",
    "\n",
    "Jika ekspresi $P \\land \\neg Q$ **tidak terpuaskan (unsatisfiable)**, maka $P \\implies Q$ pasti benar di semua model.  \n",
    "\n",
    "\n",
    "### Konsep Dasar\n",
    "\n",
    "Teknik ini dikenal sebagai **pembuktian dengan kontradiksi** (*proof by contradiction*).  \n",
    "Langkahnya: kita mengasumsikan bahwa $\\alpha$ salah, lalu menunjukkan bahwa asumsi ini menimbulkan kontradiksi dengan fakta-fakta dalam $KB$.  \n",
    "\n",
    "\n",
    "### Aturan Resolusi\n",
    "\n",
    "Aturan resolusi berbunyi:  \n",
    "\n",
    "$$\n",
    "(l_1 \\lor \\dots \\lor l_k), \\quad (m_1 \\lor \\dots \\lor m_n), \\quad (l_i \\equiv \\neg m_j) \n",
    "\\;\\;\\;\\Rightarrow\\;\\;\\;\n",
    "(l_1 \\lor \\dots \\lor l_{i-1} \\lor l_{i+1} \\lor \\dots \\lor l_k \\lor m_1 \\lor \\dots \\lor m_{j-1} \\lor m_{j+1} \\lor \\dots \\lor m_n)\n",
    "$$\n",
    "\n",
    "\n",
    "### Hasil Resolusi\n",
    "\n",
    "Proses resolusi dijalankan berulang sampai salah satu kondisi berikut:\n",
    "\n",
    "1. Tidak ada klausa baru yang bisa ditambahkan → artinya $KB \\nvDash \\alpha$.  \n",
    "2. Ditemukan **klausa kosong** → artinya $KB \\vDash \\alpha$.  \n",
    "\n",
    "Klausa kosong setara dengan **False**, karena hanya bisa muncul dari resolusi dua klausa saling berlawanan, misalnya $P$ dan $\\neg P$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konversi Kalimat ke Bentuk Normal Konjungtif (CNF)\n",
    "\n",
    "Dalam pembuktian dengan **resolusi**, algoritma tidak bisa langsung menangani kalimat logika yang rumit.  \n",
    "Karena itu, kalimat yang mengandung **implikasi (→)** dan **bi-implikasi (↔)** harus disederhanakan dulu.\n",
    "\n",
    "👉 Fakta penting: **setiap kalimat logika proposisional setara dengan bentuk konjungsi dari klausa.**  \n",
    "Bentuk ini disebut **Conjunctive Normal Form (CNF)**, yaitu **konjungsi (AND)** dari beberapa **disjungsi (OR) literal**.\n",
    "\n",
    "Contoh CNF:\n",
    "\n",
    "$$\n",
    "(A \\lor B) \\land (\\neg B \\lor C \\lor \\neg D) \\land (D \\lor \\neg E)\n",
    "$$\n",
    "\n",
    "Bentuk ini sama seperti **Product of Sums (POS)** di elektronika digital.\n",
    "\n",
    "\n",
    "## Tahapan Konversi ke CNF\n",
    "\n",
    "### 1. Ubah Bi-Implikasi ke Implikasi\n",
    "$$\n",
    "\\alpha \\iff \\beta \\equiv (\\alpha \\implies \\beta) \\land (\\beta \\implies \\alpha)\n",
    "$$\n",
    "\n",
    "Jika bagian kanan berupa kalimat majemuk:\n",
    "$$\n",
    "\\alpha \\iff (\\beta \\lor \\gamma) \\equiv (\\alpha \\implies (\\beta \\lor \\gamma)) \\land ((\\beta \\lor \\gamma) \\implies \\alpha)\n",
    "$$\n",
    "\n",
    "\n",
    "### 2. Ubah Implikasi ke Bentuk Setara\n",
    "$$\n",
    "\\alpha \\implies \\beta \\equiv \\neg \\alpha \\lor \\beta\n",
    "$$\n",
    "\n",
    "\n",
    "### 3. Pindahkan Negasi ke Literal\n",
    "Negasi hanya boleh menempel pada proposisi atomik.  \n",
    "Gunakan **Hukum De Morgan**:\n",
    "\n",
    "$$\n",
    "\\neg(\\alpha \\land \\beta) \\equiv (\\neg \\alpha \\lor \\neg \\beta)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\neg(\\alpha \\lor \\beta) \\equiv (\\neg \\alpha \\land \\neg \\beta)\n",
    "$$\n",
    "\n",
    "\n",
    "### 4. Distribusikan Disjungsi terhadap Konjungsi\n",
    "Agar sesuai format CNF, lakukan distribusi:\n",
    "\n",
    "$$\n",
    "(\\alpha \\lor (\\beta \\land \\gamma)) \\equiv (\\alpha \\lor \\beta) \\land (\\alpha \\lor \\gamma)\n",
    "$$\n",
    "\n",
    "Bentuk akhir yang kita inginkan:\n",
    "\n",
    "$$\n",
    "(\\alpha_1 \\lor \\alpha_2 \\lor \\dots) \\land (\\beta_1 \\lor \\beta_2 \\lor \\dots) \\land (\\gamma_1 \\lor \\gamma_2 \\lor \\dots)\n",
    "$$\n",
    "\n",
    "\n",
    "## Inti Proses\n",
    "- CNF = **“AND of ORs”** (konjungsi dari disjungsi literal).  \n",
    "- Proses konversi = hilangkan ↔ dan →, dorong negasi ke literal, lalu distribusikan OR atas AND.  \n",
    "- Dengan CNF, kalimat siap dipakai dalam algoritma **resolusi**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def to_cnf(s):\n",
      "    \"\"\"\n",
      "    [Page 253]\n",
      "    Convert a propositional logical sentence to conjunctive normal form.\n",
      "    That is, to the form ((A | ~B | ...) & (B | C | ...) & ...)\n",
      "    >>> to_cnf('~(B | C)')\n",
      "    (~B & ~C)\n",
      "    \"\"\"\n",
      "    s = expr(s)\n",
      "    if isinstance(s, str):\n",
      "        s = expr(s)\n",
      "    s = eliminate_implications(s)  # Steps 1, 2 from p. 253\n",
      "    s = move_not_inwards(s)  # Step 3\n",
      "    return distribute_and_over_or(s)  # Step 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(to_cnf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fungsi `to_cnf`\n",
    "Untuk mengubah sebuah kalimat logika proposisional ke bentuk **Conjunctive Normal Form (CNF)**, kita gunakan fungsi `to_cnf`.  \n",
    "\n",
    "```python\n",
    "def to_cnf(s): \n",
    "    \"\"\"\n",
    "    [Page 253]\n",
    "    Convert a propositional logical sentence to conjunctive normal form.\n",
    "    That is, to the form ((A | ~B | ...) & (B | C | ...) & ...)\n",
    "    >>> to_cnf('~(B | C)')\n",
    "    (~B & ~C)\n",
    "    \"\"\"\n",
    "    s = expr(s)\n",
    "    if isinstance(s, str):\n",
    "        s = expr(s)\n",
    "    s = eliminate_implications(s)  # Steps 1, 2 from p. 253\n",
    "    s = move_not_inwards(s)        # Step 3\n",
    "    return distribute_and_over_or(s)  # Step 4\n",
    "```\n",
    "\n",
    "### Penjelasan Tahapan\n",
    "\n",
    "1. **`eliminate_implications(s)`**\n",
    "\n",
    "   * Menyelesaikan **Langkah 1 dan 2** dari proses konversi.\n",
    "   * Semua bi-implikasi (\\$\\alpha \\iff \\beta\\$) diubah menjadi dua implikasi.\n",
    "   * Semua implikasi (\\$\\alpha \\implies \\beta\\$) diubah menjadi bentuk setara (\\$\\neg \\alpha \\lor \\beta\\$).\n",
    "\n",
    "2. **`move_not_inwards(s)`**\n",
    "\n",
    "   * Menyelesaikan **Langkah 3**.\n",
    "   * Negasi digeser ke dalam agar hanya menempel pada literal, dengan bantuan hukum De Morgan.\n",
    "   * Contoh:\n",
    "\n",
    "     $$\n",
    "     \\neg (A \\lor B) \\equiv (\\neg A \\land \\neg B)\n",
    "     $$\n",
    "\n",
    "3. **`distribute_and_over_or(s)`**\n",
    "\n",
    "   * Menyelesaikan **Langkah 4**.\n",
    "   * Melakukan distribusi disjungsi terhadap konjungsi, sehingga hasil akhir berbentuk **konjungsi dari disjungsi literal**.\n",
    "   * Contoh:\n",
    "\n",
    "     $$\n",
    "     (A \\lor (B \\land C)) \\equiv (A \\lor B) \\land (A \\lor C)\n",
    "     $$\n",
    "\n",
    "\n",
    "### Intinya\n",
    "\n",
    "* Fungsi `to_cnf` = implementasi praktis dari 4 langkah konversi CNF.\n",
    "* Setiap kalimat proposisional bisa dipaksa ke CNF → siap dipakai untuk **algoritma resolusi**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def eliminate_implications(s):\n",
      "    \"\"\"Change implications into equivalent form with only &, |, and ~ as logical operators.\"\"\"\n",
      "    s = expr(s)\n",
      "    if not s.args or is_symbol(s.op):\n",
      "        return s  # Atoms are unchanged.\n",
      "    args = list(map(eliminate_implications, s.args))\n",
      "    a, b = args[0], args[-1]\n",
      "    if s.op == '==>':\n",
      "        return b | ~a\n",
      "    elif s.op == '<==':\n",
      "        return a | ~b\n",
      "    elif s.op == '<=>':\n",
      "        return (a | ~b) & (b | ~a)\n",
      "    elif s.op == '^':\n",
      "        assert len(args) == 2  # TODO: relax this restriction\n",
      "        return (a & ~b) | (~a & b)\n",
      "    else:\n",
      "        assert s.op in ('&', '|', '~')\n",
      "        return Expr(s.op, *args)\n",
      "\n",
      "def move_not_inwards(s):\n",
      "    \"\"\"Rewrite sentence s by moving negation sign inward.\n",
      "    >>> move_not_inwards(~(A | B))\n",
      "    (~A & ~B)\n",
      "    \"\"\"\n",
      "    s = expr(s)\n",
      "    if s.op == '~':\n",
      "        def NOT(b):\n",
      "            return move_not_inwards(~b)\n",
      "\n",
      "        a = s.args[0]\n",
      "        if a.op == '~':\n",
      "            return move_not_inwards(a.args[0])  # ~~A ==> A\n",
      "        if a.op == '&':\n",
      "            return associate('|', list(map(NOT, a.args)))\n",
      "        if a.op == '|':\n",
      "            return associate('&', list(map(NOT, a.args)))\n",
      "        return s\n",
      "    elif is_symbol(s.op) or not s.args:\n",
      "        return s\n",
      "    else:\n",
      "        return Expr(s.op, *list(map(move_not_inwards, s.args)))\n",
      "\n",
      "def distribute_and_over_or(s):\n",
      "    \"\"\"Given a sentence s consisting of conjunctions and disjunctions\n",
      "    of literals, return an equivalent sentence in CNF.\n",
      "    >>> distribute_and_over_or((A & B) | C)\n",
      "    ((A | C) & (B | C))\n",
      "    \"\"\"\n",
      "    s = expr(s)\n",
      "    if s.op == '|':\n",
      "        s = associate('|', s.args)\n",
      "        if s.op != '|':\n",
      "            return distribute_and_over_or(s)\n",
      "        if len(s.args) == 0:\n",
      "            return False\n",
      "        if len(s.args) == 1:\n",
      "            return distribute_and_over_or(s.args[0])\n",
      "        conj = first(arg for arg in s.args if arg.op == '&')\n",
      "        if not conj:\n",
      "            return s\n",
      "        others = [a for a in s.args if a is not conj]\n",
      "        rest = associate('|', others)\n",
      "        return associate('&', [distribute_and_over_or(c | rest)\n",
      "                               for c in conj.args])\n",
      "    elif s.op == '&':\n",
      "        return associate('&', list(map(distribute_and_over_or, s.args)))\n",
      "    else:\n",
      "        return s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(eliminate_implications))\n",
    "print(inspect.getsource(move_not_inwards))\n",
    "print(inspect.getsource(distribute_and_over_or))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Fungsi Pendukung `to_cnf`\n",
    "\n",
    "Agar `to_cnf` bekerja, ada tiga fungsi utama yang menjalankan proses sesuai 4 langkah konversi CNF:\n",
    "\n",
    "### 1. `eliminate_implications(s)`\n",
    "\n",
    "```python\n",
    "def eliminate_implications(s):\n",
    "    \"\"\"Change implications into equivalent form with only &, |, and ~ as logical operators.\"\"\"\n",
    "    s = expr(s)\n",
    "    if not s.args or is_symbol(s.op):\n",
    "        return s  # Atoms are unchanged.\n",
    "    args = list(map(eliminate_implications, s.args))\n",
    "    a, b = args[0], args[-1]\n",
    "    if s.op == '==>':\n",
    "        return b | ~a\n",
    "    elif s.op == '<==':\n",
    "        return a | ~b\n",
    "    elif s.op == '<=>':\n",
    "        return (a | ~b) & (b | ~a)\n",
    "    elif s.op == '^':\n",
    "        assert len(args) == 2\n",
    "        return (a & ~b) | (~a & b)\n",
    "    else:\n",
    "        assert s.op in ('&', '|', '~')\n",
    "        return Expr(s.op, *args)\n",
    "```\n",
    "\n",
    "**Fungsi:**\n",
    "\n",
    "* Menghilangkan semua **implikasi (⇒)** dan **bi-implikasi (⇔)**.\n",
    "* Hasil akhirnya hanya mengandung operator `&` (AND), `|` (OR), dan `~` (NOT).\n",
    "* Contoh:\n",
    "\n",
    "$$\n",
    "(P \\implies Q) \\equiv (\\neg P \\lor Q)\n",
    "$$\n",
    "\n",
    "$$\n",
    "(P \\iff Q) \\equiv (P \\implies Q) \\land (Q \\implies P)\n",
    "$$\n",
    "\n",
    "\n",
    "### 2. `move_not_inwards(s)`\n",
    "\n",
    "```python\n",
    "def move_not_inwards(s):\n",
    "    \"\"\"Rewrite sentence s by moving negation sign inward.\n",
    "    >>> move_not_inwards(~(A | B))\n",
    "    (~A & ~B)\n",
    "    \"\"\"\n",
    "    s = expr(s)\n",
    "    if s.op == '~':\n",
    "        def NOT(b):\n",
    "            return move_not_inwards(~b)\n",
    "\n",
    "        a = s.args[0]\n",
    "        if a.op == '~':\n",
    "            return move_not_inwards(a.args[0])  # ~~A ==> A\n",
    "        if a.op == '&':\n",
    "            return associate('|', list(map(NOT, a.args)))\n",
    "        if a.op == '|':\n",
    "            return associate('&', list(map(NOT, a.args)))\n",
    "        return s\n",
    "    elif is_symbol(s.op) or not s.args:\n",
    "        return s\n",
    "    else:\n",
    "        return Expr(s.op, *list(map(move_not_inwards, s.args)))\n",
    "```\n",
    "\n",
    "**Fungsi:**\n",
    "\n",
    "* Memindahkan **negasi** supaya hanya menempel pada literal (variabel atomik).\n",
    "* Menggunakan **Hukum De Morgan** dan penyederhanaan ganda:\n",
    "\n",
    "$$\n",
    "\\neg (A \\lor B) \\equiv (\\neg A \\land \\neg B)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\neg (A \\land B) \\equiv (\\neg A \\lor \\neg B)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\neg(\\neg A) \\equiv A\n",
    "$$\n",
    "\n",
    "\n",
    "### 3. `distribute_and_over_or(s)`\n",
    "\n",
    "```python\n",
    "def distribute_and_over_or(s):\n",
    "    \"\"\"Given a sentence s consisting of conjunctions and disjunctions\n",
    "    of literals, return an equivalent sentence in CNF.\n",
    "    >>> distribute_and_over_or((A & B) | C)\n",
    "    ((A | C) & (B | C))\n",
    "    \"\"\"\n",
    "    s = expr(s)\n",
    "    if s.op == '|':\n",
    "        s = associate('|', s.args)\n",
    "        if s.op != '|':\n",
    "            return distribute_and_over_or(s)\n",
    "        if len(s.args) == 0:\n",
    "            return False\n",
    "        if len(s.args) == 1:\n",
    "            return distribute_and_over_or(s.args[0])\n",
    "        conj = first(arg for arg in s.args if arg.op == '&')\n",
    "        if not conj:\n",
    "            return s\n",
    "        others = [a for a in s.args if a is not conj]\n",
    "        rest = associate('|', others)\n",
    "        return associate('&', [distribute_and_over_or(c | rest)\n",
    "                               for c in conj.args])\n",
    "    elif s.op == '&':\n",
    "        return associate('&', list(map(distribute_and_over_or, s.args)))\n",
    "    else:\n",
    "        return s\n",
    "```\n",
    "\n",
    "**Fungsi:**\n",
    "\n",
    "* Melakukan distribusi **OR terhadap AND**, supaya hasil akhir sesuai format CNF.\n",
    "* Contoh:\n",
    "\n",
    "$$\n",
    "(A \\land B) \\lor C \\equiv (A \\lor C) \\land (B \\lor C)\n",
    "$$\n",
    "\n",
    "\n",
    "## Alur Lengkap\n",
    "\n",
    "Jadi, `to_cnf` menjalankan ketiga fungsi ini berurutan:\n",
    "\n",
    "1. **Hilangkan implikasi** → `eliminate_implications(s)`\n",
    "2. **Pindahkan negasi** → `move_not_inwards(s)`\n",
    "3. **Distribusikan OR atas AND** → `distribute_and_over_or(s)`\n",
    "\n",
    "Hasil akhirnya selalu berbentuk:\n",
    "\n",
    "$$\n",
    "(\\alpha_1 \\lor \\alpha_2 \\lor \\dots) \\land (\\beta_1 \\lor \\beta_2 \\lor \\dots) \\land \\dots\n",
    "$$\n",
    "\n",
    "siap dipakai dalam algoritma **resolusi**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mari kita coba untuk konversi beberapa kalimat menjadi cnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((A | ~B) & (B | ~A))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, B, C, D = expr('A, B, C, D')\n",
    "to_cnf(A |'<=>'| B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((A | ~B | ~C) & (B | ~A) & (C | ~A))"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_cnf(A |'<=>'| (B & C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(A & (C | B) & (D | B))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_cnf(A & (B | (C & D)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((B | ~A | C | ~D) & (A | ~A | C | ~D) & (B | ~B | C | ~D) & (A | ~B | C | ~D))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_cnf((A |'<=>'| ~B) |'==>'| (C | ~D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementasi `pl_resolution`\n",
    "\n",
    "Setelah memahami fungsi `to_cnf`, kita bisa lihat bagaimana fungsi ini digunakan dalam algoritma **Proof by Resolution**.  \n",
    "Berikut kode dari fungsi `pl_resolution`:\n",
    "\n",
    "```python\n",
    "def pl_resolution(kb, alpha):\n",
    "    \"\"\"\n",
    "    [Figure 7.12]\n",
    "    Propositional-logic resolution: say if alpha follows from KB.\n",
    "    >>> pl_resolution(horn_clauses_KB, A)\n",
    "    True\n",
    "    \"\"\"\n",
    "    clauses = kb.clauses + conjuncts(to_cnf(~alpha))\n",
    "    new = set()\n",
    "    while True:\n",
    "        n = len(clauses)\n",
    "        pairs = [(clauses[i], clauses[j])\n",
    "                 for i in range(n) for j in range(i + 1, n)]\n",
    "        for (ci, cj) in pairs:\n",
    "            resolvents = pl_resolve(ci, cj)\n",
    "            if False in resolvents:\n",
    "                return True\n",
    "            new = new.union(set(resolvents))\n",
    "        if new.issubset(set(clauses)):\n",
    "            return False\n",
    "        for c in new:\n",
    "            if c not in clauses:\n",
    "                clauses.append(c)\n",
    "```\n",
    "\n",
    "### Alur Kerja `pl_resolution`\n",
    "\n",
    "1. **Persiapan klausa**\n",
    "\n",
    "   * Semua klausa dalam basis pengetahuan (`kb.clauses`) digabung dengan hasil konversi CNF dari negasi query `~alpha`.\n",
    "   * Hal ini sesuai prinsip resolusi: untuk membuktikan $\\text{KB} \\vDash \\alpha$, kita cek apakah $\\text{KB} \\land \\neg \\alpha$ tidak terpuaskan.\n",
    "\n",
    "2. **Inisialisasi**\n",
    "\n",
    "   * Variabel `new` dibuat sebagai himpunan kosong untuk menampung resolvent (klausa hasil resolusi).\n",
    "\n",
    "3. **Loop utama**\n",
    "\n",
    "   * Semua pasangan klausa dalam `clauses` diambil.\n",
    "   * Untuk setiap pasangan `(ci, cj)`, dijalankan fungsi `pl_resolve` untuk mencari resolvent.\n",
    "\n",
    "4. **Pengecekan kontradiksi**\n",
    "\n",
    "   * Jika ada resolvent yang menghasilkan `False` (klausa kosong), berarti kontradiksi ditemukan → $\\text{KB} \\vDash \\alpha$.\n",
    "   * Fungsi langsung mengembalikan `True`.\n",
    "\n",
    "5. **Update klausa**\n",
    "\n",
    "   * Semua resolvent baru dimasukkan ke dalam `new`.\n",
    "   * Jika `new` hanyalah subset dari klausa lama (tidak ada klausa baru yang muncul), artinya tidak ada resolusi lebih lanjut → algoritma berhenti dengan hasil `False` (tidak terbukti).\n",
    "   * Jika ada klausa baru, tambahkan ke `clauses` lalu ulangi proses.\n",
    "\n",
    "### Intuisi\n",
    "\n",
    "* **Kunci resolusi:** cari pasangan klausa yang punya literal saling berlawanan, lalu gabungkan sisanya.\n",
    "* **Tujuan:** terus menghasilkan klausa baru sampai:\n",
    "\n",
    "  1. Ketemu **klausa kosong** (kontradiksi → query terbukti).\n",
    "  2. Tidak ada klausa baru lagi (tidak terbukti).\n",
    "\n",
    "Dengan demikian, `pl_resolution` bekerja sebagai prosedur sistematis untuk mengecek entailment menggunakan prinsip **proof by contradiction** dengan bantuan konversi ke **CNF**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def pl_resolution(kb, alpha):\n",
      "    \"\"\"\n",
      "    [Figure 7.12]\n",
      "    Propositional-logic resolution: say if alpha follows from KB.\n",
      "    >>> pl_resolution(horn_clauses_KB, A)\n",
      "    True\n",
      "    \"\"\"\n",
      "    clauses = kb.clauses + conjuncts(to_cnf(~alpha))\n",
      "    new = set()\n",
      "    while True:\n",
      "        n = len(clauses)\n",
      "        pairs = [(clauses[i], clauses[j])\n",
      "                 for i in range(n) for j in range(i + 1, n)]\n",
      "        for (ci, cj) in pairs:\n",
      "            resolvents = pl_resolve(ci, cj)\n",
      "            if False in resolvents:\n",
      "                return True\n",
      "            new = new.union(set(resolvents))\n",
      "        if new.issubset(set(clauses)):\n",
      "            return False\n",
      "        for c in new:\n",
      "            if c not in clauses:\n",
      "                clauses.append(c)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(pl_resolution))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_resolution(wumpus_kb, ~P11), pl_resolution(wumpus_kb, P11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_resolution(wumpus_kb, ~P22), pl_resolution(wumpus_kb, P22)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hasil Uji `pl_resolution` pada Wumpus KB\n",
    "\n",
    "Kita menguji dua query berbeda pada basis pengetahuan Wumpus menggunakan fungsi `pl_resolution`.\n",
    "\n",
    "### 1. Query pada Kotak (1,1)\n",
    "\n",
    "```python\n",
    "pl_resolution(wumpus_kb, ~P11), pl_resolution(wumpus_kb, P11)\n",
    "# Hasil: (True, False)\n",
    "```\n",
    "\n",
    "**Penjelasan:**\n",
    "* `pl_resolution(wumpus_kb, ~P11) → True`\n",
    "  Artinya basis pengetahuan **dapat membuktikan bahwa di kotak (1,1) tidak ada pit**.\n",
    "  Hal ini sesuai aturan awal permainan Wumpus World: posisi awal pemain (1,1) selalu aman.\n",
    "\n",
    "* `pl_resolution(wumpus_kb, P11) → False`\n",
    "  Basis pengetahuan **tidak bisa membuktikan bahwa ada pit di (1,1)**, karena memang informasi dalam KB justru menyatakan sebaliknya.\n",
    "\n",
    "\n",
    "### 2. Query pada Kotak (2,2)\n",
    "\n",
    "```python\n",
    "pl_resolution(wumpus_kb, ~P22), pl_resolution(wumpus_kb, P22)\n",
    "# Hasil: (False, False)\n",
    "```\n",
    "\n",
    "**Penjelasan:**\n",
    "\n",
    "* `pl_resolution(wumpus_kb, ~P22) → False`\n",
    "  Basis pengetahuan **tidak bisa membuktikan bahwa (2,2) bebas pit**.\n",
    "  Informasi yang ada belum cukup untuk menyimpulkan aman atau tidak.\n",
    "\n",
    "* `pl_resolution(wumpus_kb, P22) → False`\n",
    "  Basis pengetahuan **juga tidak bisa membuktikan bahwa ada pit di (2,2)**.\n",
    "\n",
    "Dengan kata lain, posisi (2,2) masih **tidak diketahui statusnya** berdasarkan informasi yang tersedia.\n",
    "\n",
    "### Kesimpulan\n",
    "\n",
    "* Pada kotak awal (1,1), KB dengan jelas **meng-entail** bahwa tidak ada pit.\n",
    "* Pada kotak (2,2), KB belum punya informasi yang cukup, sehingga baik `P22` maupun `~P22` tidak bisa dibuktikan.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward dan Backward Chaining\n",
    "\n",
    "Sebelumnya kita sudah membahas dua algoritma untuk mengecek apakah sebuah kalimat di-*entail* oleh basis pengetahuan (`KB`).  \n",
    "Di sini kita perkenalkan **algoritma ketiga**, yaitu *forward chaining* dan *backward chaining*.  \n",
    "\n",
    "Perbedaan utamanya: tujuan sekarang adalah menentukan apakah basis pengetahuan yang hanya berisi **definite clause** dapat meng-entail sebuah simbol proposisi tunggal $q$ (query).  \n",
    "Namun, ada satu syarat penting: **basis pengetahuan hanya boleh berisi Horn Clauses**.\n",
    "\n",
    "#### Horn Clauses\n",
    "\n",
    "- **Horn Clause** adalah disjungsi (OR) dari beberapa literal dengan **paling banyak satu literal positif**.  \n",
    "- Jika sebuah Horn Clause memiliki tepat satu literal positif, maka ia disebut **Definite Clause**.  \n",
    "- Jika Horn Clause hanya berisi literal positif tunggal, ia disebut **Fact**.  \n",
    "\n",
    "Contoh Horn Clause:  \n",
    "\n",
    "$$\n",
    "\\neg a \\lor \\neg b \\lor \\neg c \\lor z\n",
    "$$\n",
    "\n",
    "Dengan menggunakan Hukum De Morgan, bentuk ini bisa ditulis ulang menjadi:  \n",
    "\n",
    "$$\n",
    "a \\land b \\land c \\;\\;\\implies\\;\\; z\n",
    "$$\n",
    "\n",
    "Artinya: jika $a$, $b$, dan $c$ semuanya benar, maka $z$ juga dapat disimpulkan benar.  \n",
    "Bentuk ini mirip dengan cara manusia memproses fakta dan pengetahuan untuk menghasilkan kesimpulan baru.\n",
    "\n",
    "#### Keunggulan Horn Clauses\n",
    "\n",
    "1. **Definite Clause dapat ditulis sebagai implikasi**  \n",
    "   - Premis (body) berupa konjungsi literal positif.  \n",
    "   - Kesimpulan (head) berupa satu literal positif.  \n",
    "   - Contoh:  \n",
    "\n",
    "     $$\n",
    "     a \\land b \\implies z\n",
    "     $$  \n",
    "\n",
    "   - Sebuah literal positif tunggal disebut **fact**.  \n",
    "   - Dengan bentuk seperti ini, aturan lebih mudah dipahami maupun diimplementasikan.\n",
    "\n",
    "2. **Bisa digunakan pada Forward dan Backward Chaining**  \n",
    "   - *Forward chaining* bekerja dengan menambahkan fakta baru secara progresif.  \n",
    "   - *Backward chaining* bekerja dengan menelusuri mundur dari query menuju fakta dasar.  \n",
    "   - Kedua algoritma ini berjalan efisien pada Horn Clauses karena bentuknya sudah sangat terstruktur.\n",
    "\n",
    "3. **Kompleksitas Linear**  \n",
    "   - Keputusan entailment dengan Horn Clauses hanya memerlukan traversal setiap klausa dalam basis pengetahuan **paling banyak sekali**.  \n",
    "   - Hal ini membuat proses inferensi jauh lebih efisien dibanding metode enumerasi atau resolusi umum.\n",
    "\n",
    "\n",
    "#### Implementasi di Kode\n",
    "\n",
    "Inferensi dengan *forward chaining* dapat diuji menggunakan fungsi:\n",
    "\n",
    "```python\n",
    "pl_fc_entails(KB, q)\n",
    "```\n",
    "\n",
    "Catatan penting:\n",
    "\n",
    "* Basis pengetahuan yang dipakai bukanlah instansi `KB` biasa.\n",
    "* `KB` di sini adalah objek dari kelas **`PropDefiniteKB`**, turunan dari `PropKB` yang dimodifikasi khusus untuk menyimpan **Definite Clause**.\n",
    "* Perbedaan utama ada pada metode bantu tambahan yang dapat mengembalikan daftar klausa dalam KB yang memiliki simbol tertentu di bagian premis.\n",
    "\n",
    "Dengan cara ini, forward chaining dapat lebih cepat menemukan aturan mana saja yang relevan ketika sebuah fakta baru muncul.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def clauses_with_premise(self, p):\n",
      "        \"\"\"Return a list of the clauses in KB that have p in their premise.\n",
      "        This could be cached away for O(1) speed, but we'll recompute it.\"\"\"\n",
      "        return [c for c in self.clauses if c.op == '==>' and p in conjuncts(c.args[0])]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(PropDefiniteKB.clauses_with_premise))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Fungsi `clauses_with_premise`\n",
    "\n",
    "```python\n",
    "psource(PropDefiniteKB.clauses_with_premise)\n",
    "def clauses_with_premise(self, p):\n",
    "    \"\"\"Return a list of the clauses in KB that have p in their premise.\n",
    "    This could be cached away for O(1) speed, but we'll recompute it.\"\"\"\n",
    "    return [c for c in self.clauses if c.op == '==>' and p in conjuncts(c.args[0])]\n",
    "```\n",
    "\n",
    "## Fungsi\n",
    "\n",
    "Digunakan untuk mengambil semua klausa dalam Knowledge Base (KB) yang memiliki simbol tertentu `p` pada bagian premis (bagian kiri implikasi).\n",
    "\n",
    "## Alur Kerja\n",
    "\n",
    "1. `self.clauses` → daftar semua klausa dalam basis pengetahuan.\n",
    "2. `c.op == '==>'` → hanya ambil klausa yang berupa implikasi (definite clause).\n",
    "3. `c.args[0]` → mengambil bagian premis dari klausa (bagian kiri sebelum `==>`).\n",
    "4. `conjuncts(c.args[0])` → memecah premis menjadi daftar konjungsi.\n",
    "5. `p in conjuncts(c.args[0])` → mengecek apakah simbol `p` ada di dalam premis.\n",
    "6. Hasil akhir berupa list semua klausa yang memenuhi kondisi di atas.\n",
    "\n",
    "## Intuisi\n",
    "\n",
    "Premis adalah syarat yang harus dipenuhi agar klausa berlaku.\n",
    "Fungsi ini digunakan untuk mencari aturan yang relevan dengan simbol tertentu di bagian premis.\n",
    "\n",
    "## Contoh\n",
    "\n",
    "Misalkan KB berisi klausa:\n",
    "\n",
    "1. `A & B ==> C`\n",
    "2. `D ==> E`\n",
    "3. `B ==> F`\n",
    "\n",
    "Jika dipanggil:\n",
    "\n",
    "```python\n",
    "clauses_with_premise(\"B\")\n",
    "```\n",
    "\n",
    "Maka hasilnya adalah:\n",
    "\n",
    "* `A & B ==> C`\n",
    "* `B ==> F`\n",
    "\n",
    "Kedua klausa tersebut dipilih karena premisnya mengandung `B`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fungsi `pl_fc_entails`\n",
    "\n",
    "```python\n",
    "print(inspect.getsource(pl_fc_entails))\n",
    "def pl_fc_entails(kb, q):\n",
    "    \"\"\"\n",
    "    [Figure 7.15]\n",
    "    Use forward chaining to see if a PropDefiniteKB entails symbol q.\n",
    "    >>> pl_fc_entails(horn_clauses_KB, expr('Q'))\n",
    "    True\n",
    "    \"\"\"\n",
    "    count = {c: len(conjuncts(c.args[0])) for c in kb.clauses if c.op == '==>'}\n",
    "    inferred = defaultdict(bool)\n",
    "    agenda = [s for s in kb.clauses if is_prop_symbol(s.op)]\n",
    "    while agenda:\n",
    "        p = agenda.pop()\n",
    "        if p == q:\n",
    "            return True\n",
    "        if not inferred[p]:\n",
    "            inferred[p] = True\n",
    "            for c in kb.clauses_with_premise(p):\n",
    "                count[c] -= 1\n",
    "                if count[c] == 0:\n",
    "                    agenda.append(c.args[1])\n",
    "    return False\n",
    "```\n",
    "## Fungsi\n",
    "\n",
    "Digunakan untuk melakukan **forward chaining** pada *Propositional Definite Knowledge Base (PropDefiniteKB)*, untuk mengecek apakah basis pengetahuan dapat **menyimpulkan** suatu simbol query `q`.\n",
    "\n",
    "## Alur Kerja\n",
    "\n",
    "1. `count` → menghitung berapa banyak premis (konjungsi) yang harus dipenuhi pada tiap klausa implikasi.\n",
    "2. `inferred` → penanda apakah suatu simbol sudah pernah disimpulkan (`True/False`).\n",
    "3. `agenda` → daftar simbol fakta awal (proposisi yang langsung diketahui dari KB).\n",
    "4. **Loop utama**:\n",
    "\n",
    "   * Ambil simbol `p` dari `agenda`.\n",
    "   * Jika `p == q` → kembalikan `True` (berarti query berhasil disimpulkan).\n",
    "   * Jika `p` belum pernah disimpulkan:\n",
    "\n",
    "     * Tandai `p` sebagai sudah disimpulkan.\n",
    "     * Cek klausa yang premisnya mengandung `p`.\n",
    "     * Kurangi `count[c]` (sisa syarat klausa `c`).\n",
    "     * Jika `count[c] == 0`, artinya semua syarat terpenuhi → tambahkan kesimpulan (`c.args[1]`) ke `agenda`.\n",
    "5. Jika `agenda` habis tanpa menemukan `q`, maka kembalikan `False`.\n",
    "\n",
    "## Intuisi\n",
    "\n",
    "Algoritma ini meniru cara kita **menarik kesimpulan dari fakta-fakta yang ada**.\n",
    "Kita mulai dengan fakta awal → cek aturan mana yang bisa dipicu → hasil aturan ditambahkan sebagai fakta baru → ulangi terus sampai query ditemukan atau tidak ada fakta baru lagi.\n",
    "\n",
    "## Contoh\n",
    "\n",
    "Misalkan KB berisi klausa:\n",
    "\n",
    "1. `A ==> B`\n",
    "2. `B & C ==> D`\n",
    "3. `D ==> E`\n",
    "4. Fakta awal: `A`, `C`\n",
    "\n",
    "Jika kita jalankan:\n",
    "\n",
    "```python\n",
    "pl_fc_entails(KB, E)\n",
    "```\n",
    "\n",
    "Maka prosesnya:\n",
    "\n",
    "* Dari `A`, disimpulkan `B`.\n",
    "* Karena `B` dan `C` ada, maka bisa simpulkan `D`.\n",
    "* Dari `D`, simpulkan `E`.\n",
    "* Query `E` berhasil ditemukan → hasil `True`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def pl_fc_entails(kb, q):\n",
      "    \"\"\"\n",
      "    [Figure 7.15]\n",
      "    Use forward chaining to see if a PropDefiniteKB entails symbol q.\n",
      "    >>> pl_fc_entails(horn_clauses_KB, expr('Q'))\n",
      "    True\n",
      "    \"\"\"\n",
      "    count = {c: len(conjuncts(c.args[0])) for c in kb.clauses if c.op == '==>'}\n",
      "    inferred = defaultdict(bool)\n",
      "    agenda = [s for s in kb.clauses if is_prop_symbol(s.op)]\n",
      "    while agenda:\n",
      "        p = agenda.pop()\n",
      "        if p == q:\n",
      "            return True\n",
      "        if not inferred[p]:\n",
      "            inferred[p] = True\n",
      "            for c in kb.clauses_with_premise(p):\n",
      "                count[c] -= 1\n",
      "                if count[c] == 0:\n",
      "                    agenda.append(c.args[1])\n",
      "    return False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(pl_fc_entails))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Penjelasan Fungsi `pl_fc_entails`\n",
    "\n",
    "Fungsi ini menerima sebuah **knowledge base (KB)** berupa instance dari `PropDefiniteKB` dan sebuah query `q` sebagai input. <br><br>\n",
    "\n",
    "* `count` pada awalnya menyimpan jumlah simbol dalam **premis** dari setiap kalimat dalam knowledge base.\n",
    "* Fungsi pembantu `conjuncts` digunakan untuk memecah suatu kalimat berdasarkan operator konjungsi (`&`).\n",
    "* `inferred` diinisialisasi sebagai **defaultdict boolean**.\n",
    "  Variabel ini digunakan untuk mengecek apakah semua premis dari setiap klausa dalam agenda sudah berhasil disimpulkan.\n",
    "* `agenda` pada awalnya berisi daftar klausa yang sudah diketahui benar oleh knowledge base.\n",
    "  Fungsi pembantu `is_prop_symbol` digunakan untuk mengecek apakah simbol yang diberikan adalah simbol logika proposisional yang valid. <br><br>\n",
    "\n",
    "Selanjutnya kita melakukan iterasi melalui `agenda`, dengan mengambil (pop) sebuah simbol `p` pada setiap iterasi.\n",
    "\n",
    "* Jika query `q` sama dengan `p`, maka dapat dipastikan bahwa entailment berlaku (**entails = True**).\n",
    "* Agenda kemudian diproses, dengan mengurangi `count` sebanyak satu untuk setiap implikasi yang memiliki premis `p`.\n",
    "* Sebuah **konklusi** ditambahkan ke agenda ketika nilai `count` mencapai nol.\n",
    "  Hal ini berarti semua premis dari implikasi tersebut sudah diketahui benar. <br><br>\n",
    "\n",
    "`clauses_with_premise` adalah metode penting dari kelas `PropDefiniteKB`.\n",
    "Metode ini mengembalikan daftar klausa dalam knowledge base yang memiliki simbol `p` pada bagian premisnya. <br><br>\n",
    "\n",
    "Sekarang setelah kita memahami cara kerja fungsi ini, mari kita lihat beberapa contoh penggunaannya.\n",
    "Namun sebelum itu, kita perlu mendefinisikan knowledge base terlebih dahulu.\n",
    "Kita akan mengasumsikan bahwa klausa-klausa berikut diketahui benar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clauses = ['(B & F)==>E', \n",
    "           '(A & E & F)==>G', \n",
    "           '(B & C)==>F', \n",
    "           '(A & B)==>D', \n",
    "           '(E & F)==>H', \n",
    "           '(H & I)==>J',\n",
    "           'A', \n",
    "           'B', \n",
    "           'C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Sekarang kita akan tell (menambahkan) informasi ini ke dalam knowledge base kita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "definite_clauses_KB = PropDefiniteKB()\n",
    "for clause in clauses:\n",
    "    definite_clauses_KB.tell(expr(clause))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check if our knowledge base entails the following queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_fc_entails(definite_clauses_KB, expr('G'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_fc_entails(definite_clauses_KB, expr('H'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_fc_entails(definite_clauses_KB, expr('I'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_fc_entails(definite_clauses_KB, expr('J'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita punya klausa:\n",
    "\n",
    "```\n",
    "1. (B & F)     ==> E\n",
    "2. (A & E & F) ==> G\n",
    "3. (B & C)     ==> F\n",
    "4. (A & B)     ==> D\n",
    "5. (E & F)     ==> H\n",
    "6. (H & I)     ==> J\n",
    "7. A\n",
    "8. B\n",
    "9. C\n",
    "```\n",
    "\n",
    "Fakta awal = **A, B, C**.\n",
    "Algoritma **forward chaining (`pl_fc_entails`)** akan menambahkan fakta baru setiap kali semua premis dari sebuah aturan terpenuhi.\n",
    "\n",
    "\n",
    "### 1. `pl_fc_entails(..., G)`\n",
    "\n",
    "* Dari fakta awal `B` dan `C`, aturan (3) aktif → **F**.\n",
    "* Dari `B` dan `F`, aturan (1) aktif → **E**.\n",
    "* Sekarang punya `A, B, C, F, E`.\n",
    "* Aturan (2): `(A & E & F) ==> G`. Semua premis **A, E, F** benar → maka **G** dapat disimpulkan.\n",
    "\n",
    "**Hasil:** `True` (KB **menyimpulkan G**).\n",
    "\n",
    "### 2. `pl_fc_entails(..., H)`\n",
    "\n",
    "* Dari langkah di atas kita sudah punya **E** dan **F**.\n",
    "* Aturan (5): `(E & F) ==> H`. Semua premis terpenuhi → **H** bisa disimpulkan.\n",
    "\n",
    "**Hasil:** `True` (KB **menyimpulkan H**).\n",
    "\n",
    "\n",
    "### 3. `pl_fc_entails(..., I)`\n",
    "\n",
    "* Coba cek apakah ada aturan yang bisa menghasilkan **I**.\n",
    "* Tidak ada aturan dengan konsekuen `I`, dan **I** juga bukan fakta awal.\n",
    "\n",
    "**Hasil:** `False` (KB **tidak bisa menyimpulkan I**).\n",
    "\n",
    "\n",
    "### 4. `pl_fc_entails(..., J)`\n",
    "\n",
    "* Aturan (6): `(H & I) ==> J`.\n",
    "* Kita sudah punya **H** (benar), tapi **I** tidak pernah bisa dibuktikan (lihat poin 3).\n",
    "* Karena salah satu premis gagal, aturan (6) tidak bisa memicu → **J** tidak dapat disimpulkan.\n",
    "\n",
    "**Hasil:** `False` (KB **tidak bisa menyimpulkan J**).\n",
    "\n",
    "### Ringkasan Hasil\n",
    "\n",
    "| Query | Hasil | Alasan                                                       |\n",
    "| ----- | ----- | ------------------------------------------------------------ |\n",
    "| G     | True  | Bisa diturunkan dari A, B, C melalui aturan (3) → (1) → (2). |\n",
    "| H     | True  | Bisa diturunkan dari E dan F melalui aturan (5).             |\n",
    "| I     | False | Tidak ada aturan/fakta yang memberi I.                       |\n",
    "| J     | False | Butuh H dan I, tapi I tidak terbukti → J gagal diturunkan.   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Base First-Order Logic: FolKB\n",
    "\n",
    "Kelas FolKB dapat digunakan untuk merepresentasikan knowledge base yang berisi kalimat-kalimat First-order logic.\n",
    "Cara inisialisasi dan penggunaannya sama seperti PropKB, hanya saja klausa yang digunakan adalah klausa definit first-order.\n",
    "\n",
    "Pada bagian selanjutnya, kita akan melihat bagaimana cara menuliskan klausa-klausa tersebut untuk membuat sebuah database dan melakukan query terhadapnya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Criminal KB\n",
    "\n",
    "Pada bagian ini kita akan membuat sebuah `FolKB` berdasarkan paragraf berikut: <br/>\n",
    "\n",
    "*“Hukum menyatakan bahwa merupakan tindak kejahatan bagi seorang warga Amerika untuk menjual senjata kepada negara-negara yang bermusuhan. Negara Nono, musuh Amerika, memiliki beberapa misil, dan semua misil tersebut dijual kepadanya oleh Kolonel West, yang merupakan warga Amerika.”* <br/>\n",
    "\n",
    "Langkah pertama adalah mengekstrak fakta-fakta dari paragraf tersebut dan mengonversinya menjadi **klausa definit first-order**.\n",
    "\n",
    "Melakukan ekstraksi fakta dari data secara otomatis memang merupakan tugas yang menantang. Untungnya, kita hanya memiliki sebuah paragraf singkat sehingga ekstraksi dan konversi dapat dilakukan secara manual.\n",
    "\n",
    "Klausa-klausa tersebut akan disimpan dalam sebuah list yang diberi nama `clauses`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clauses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*“... merupakan tindak kejahatan bagi seorang warga Amerika untuk menjual senjata kepada negara-negara yang bermusuhan”*  \n",
    "<br/>\n",
    "\n",
    "Kata kunci yang perlu diperhatikan adalah **'crime'**, **'American'**, **'sell'**, **'weapon'**, dan **'hostile'**.  \n",
    "Kita gunakan simbol predikat untuk merepresentasikan makna dari kata-kata tersebut:\n",
    "\n",
    "- `Criminal(x)`: `x` adalah seorang penjahat  \n",
    "- `American(x)`: `x` adalah warga Amerika  \n",
    "- `Sells(x, y, z)`: `x` menjual `y` kepada `z`  \n",
    "- `Weapon(x)`: `x` adalah sebuah senjata  \n",
    "- `Hostile(x)`: `x` adalah negara bermusuhan  \n",
    "\n",
    "Sekarang kita gabungkan dengan penamaan variabel yang sesuai untuk menggambarkan arti kalimat tersebut.  \n",
    "Seorang penjahat `x` adalah juga seorang Amerika `x` yang menjual senjata `y` kepada `z`, di mana `z` adalah sebuah negara bermusuhan.  \n",
    "\n",
    "$$\n",
    "\\text{American}(x) \\land \\text{Weapon}(y) \\land \\text{Sells}(x, y, z) \\land \\text{Hostile}(z) \\implies \\text{Criminal}(x)\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clauses.append(expr(\"(American(x) & Weapon(y) & Sells(x, y, z) & Hostile(z)) ==> Criminal(x)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*“Negara Nono, musuh Amerika”*  \n",
    "<br/>\n",
    "\n",
    "Sekarang kita tahu bahwa **Nono adalah musuh Amerika**.  \n",
    "Kita merepresentasikan negara-negara ini menggunakan simbol konstanta `Nono` dan `America`.  \n",
    "Relasi permusuhan ditunjukkan dengan simbol predikat `Enemy`.  \n",
    "\n",
    "$$\n",
    "\\text{Enemy}(\\text{Nono}, \\text{America})\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clauses.append(expr(\"Enemy(Nono, America)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*“Nono ... memiliki beberapa misil”*  \n",
    "<br/>\n",
    "\n",
    "Pernyataan ini menunjukkan **eksistensi sebuah misil** yang dimiliki oleh Nono.  \n",
    "\n",
    "$$\n",
    "\\exists x \\ \\text{Owns}(\\text{Nono}, x) \\land \\text{Missile}(x)\n",
    "$$\n",
    "\n",
    "Dengan menggunakan **eksistensial instantiation**, kita memperkenalkan sebuah konstanta baru `M1` yang merepresentasikan misil milik Nono.  \n",
    "\n",
    "$$\n",
    "\\text{Owns}(\\text{Nono}, \\text{M1}), \\quad \\text{Missile}(\\text{M1})\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clauses.append(expr(\"Owns(Nono, M1)\"))\n",
    "clauses.append(expr(\"Missile(M1)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "*“Semua misil milik Nono dijual kepadanya oleh Kolonel West”*  \n",
    "<br/>\n",
    "\n",
    "Artinya, jika Nono memiliki sesuatu dan benda tersebut tergolong sebagai misil, maka benda itu dijual kepada Nono oleh West.  \n",
    "\n",
    "$$\n",
    "\\text{Missile}(x) \\land \\text{Owns}(\\text{Nono}, x) \\implies \\text{Sells}(\\text{West}, x, \\text{Nono})\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clauses.append(expr(\"(Missile(x) & Owns(Nono, x)) ==> Sells(West, x, Nono)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*“West, yang merupakan orang Amerika”*  \n",
    "<br/>\n",
    "\n",
    "Pernyataan ini berarti bahwa **West adalah seorang warga Amerika**.  \n",
    "\n",
    "$$\n",
    "\\text{American}(\\text{West})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clauses.append(expr(\"American(West)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita juga tahu, berdasarkan pemahaman bahasa, bahwa **misil adalah senjata** dan bahwa **musuh Amerika termasuk sebagai “hostile”**.  \n",
    "\n",
    "$$\n",
    "\\text{Missile}(x) \\implies \\text{Weapon}(x)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Enemy}(x, \\text{America}) \\implies \\text{Hostile}(x)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clauses.append(expr(\"Missile(x) ==> Weapon(x)\"))\n",
    "clauses.append(expr(\"Enemy(x, America) ==> Hostile(x)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang setelah kita mengonversi informasi menjadi **klausa definit first-order**,  \n",
    "kita dapat membuat **knowledge base first-order logic** kita.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crime_kb = FolKB(clauses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fungsi `subst`\n",
    "\n",
    "```python\n",
    "def subst(s, x):\n",
    "    \"\"\"Substitute the substitution s into the expression x.\n",
    "    >>> subst({x: 42, y:0}, F(x) + y)\n",
    "    (F(42) + 0)\n",
    "    \"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return [subst(s, xi) for xi in x]\n",
    "    elif isinstance(x, tuple):\n",
    "        return tuple([subst(s, xi) for xi in x])\n",
    "    elif not isinstance(x, Expr):\n",
    "        return x\n",
    "    elif is_var_symbol(x.op):\n",
    "        return s.get(x, x)\n",
    "    else:\n",
    "        return Expr(x.op, *[subst(s, arg) for arg in x.args])\n",
    "```\n",
    "\n",
    "## Fungsi\n",
    "\n",
    "`subst` adalah fungsi pembantu (*helper function*) yang digunakan untuk **mengganti variabel dengan nilai yang diberikan** dalam pernyataan logika first-order.\n",
    "Fungsi ini sangat berguna dalam algoritma lanjutan seperti *unification* dan *inference*.\n",
    "\n",
    "## Alur Kerja\n",
    "\n",
    "1. Jika `x` berupa **list**, maka lakukan substitusi untuk setiap elemen list.\n",
    "2. Jika `x` berupa **tuple**, maka lakukan substitusi untuk setiap elemen tuple.\n",
    "3. Jika `x` **bukan** sebuah ekspresi (`Expr`), kembalikan `x` apa adanya (basis kasus).\n",
    "4. Jika `x` adalah **variabel**, cek apakah variabel tersebut ada di dalam substitusi `s`:\n",
    "\n",
    "   * Jika ada, ganti dengan nilai dari `s`.\n",
    "   * Jika tidak, biarkan tetap `x`.\n",
    "5. Jika `x` adalah sebuah **ekspresi kompleks**, buat ekspresi baru dengan operator yang sama, lalu lakukan substitusi rekursif pada setiap argumen.\n",
    "\n",
    "## Contoh\n",
    "\n",
    "```python\n",
    ">>> subst({x: 42, y: 0}, F(x) + y)\n",
    "(F(42) + 0)\n",
    "```\n",
    "\n",
    "Artinya: variabel `x` diganti dengan `42` dan `y` diganti dengan `0`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def subst(s, x):\n",
      "    \"\"\"Substitute the substitution s into the expression x.\n",
      "    >>> subst({x: 42, y:0}, F(x) + y)\n",
      "    (F(42) + 0)\n",
      "    \"\"\"\n",
      "    if isinstance(x, list):\n",
      "        return [subst(s, xi) for xi in x]\n",
      "    elif isinstance(x, tuple):\n",
      "        return tuple([subst(s, xi) for xi in x])\n",
      "    elif not isinstance(x, Expr):\n",
      "        return x\n",
      "    elif is_var_symbol(x.op):\n",
      "        return s.get(x, x)\n",
      "    else:\n",
      "        return Expr(x.op, *[subst(s, arg) for arg in x.args])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(subst))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berikut adalah contoh bagaimana fungsi `subst` dapat digunakan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Owns(Nono, M1)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subst({x: expr('Nono'), y: expr('M1')}, expr('Owns(x, y)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferensi dalam First-Order Logic\n",
    "\n",
    "Pada bagian ini kita akan membahas algoritma **forward chaining** dan **backward chaining** untuk `FolKB`.  \n",
    "Kedua algoritma tersebut bergantung pada sebuah proses yang disebut **unifikasi (unification)**,  \n",
    "yang merupakan komponen kunci dari semua algoritma inferensi first-order.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unifikasi\n",
    "\n",
    "Kadang kita perlu mencari **substitusi** yang membuat dua ekspresi logika berbeda terlihat **identik**.  \n",
    "Proses ini disebut **unifikasi (unification)**, dan dilakukan oleh algoritma `unify`.  \n",
    "\n",
    "Algoritma ini menerima dua kalimat sebagai input dan mengembalikan sebuah *unifier* jika ada.  \n",
    "*Unifier* adalah sebuah dictionary yang menyimpan substitusi yang diperlukan agar kedua kalimat menjadi identik.  \n",
    "\n",
    "Prosesnya dilakukan dengan **merecursive unifikasi komponen** dari sebuah kalimat,  \n",
    "di mana unifikasi antara simbol variabel `var` dengan simbol konstanta `Const` direpresentasikan sebagai pemetaan:  \n",
    "\n",
    "$$\n",
    "\\{ \\text{var} : \\text{Const} \\}\n",
    "$$\n",
    "\n",
    "Mari kita lihat beberapa contoh.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{x: 3}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unify(expr('x'), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{x: B}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unify(expr('A(x)'), expr('A(B)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{x: Bella, y: Dobby}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unify(expr('Cat(x) & Dog(Dobby)'), expr('Cat(Bella) & Dog(y)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalam kasus di mana **tidak ada substitusi** yang dapat membuat dua kalimat menjadi terunifikasi,  \n",
    "fungsi akan mengembalikan nilai `None`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(unify(expr('Cat(x)'), expr('Dog(Dobby)')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita juga perlu berhati-hati agar tidak secara tidak sengaja menggunakan **nama variabel yang sama**.  \n",
    "Algoritma `unify` akan menganggapnya sebagai satu variabel yang sama,  \n",
    "sehingga mencegah variabel tersebut untuk memiliki lebih dari satu nilai.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(unify(expr('Cat(x) & Dog(Dobby)'), expr('Cat(Bella) & Dog(x)')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritma Forward Chaining\n",
    "\n",
    "Di sini kita membahas algoritma forward chaining sederhana seperti yang ditunjukkan pada *Figure 9.3*.  \n",
    "Kita melihat setiap aturan dalam knowledge base dan memeriksa apakah premisnya dapat dipenuhi.  \n",
    "\n",
    "Proses ini dilakukan dengan mencari **substitusi** yang menyatukan (unify) setiap premis dengan sebuah klausa di `KB`.  \n",
    "Jika kita dapat melakukan unifikasi pada premis-premis tersebut, maka kesimpulan (dengan substitusi yang sesuai)  \n",
    "ditambahkan ke dalam `KB`.  \n",
    "\n",
    "Proses inferensi ini diulangi hingga:  \n",
    "- Query dapat dijawab, atau  \n",
    "- Tidak ada lagi kalimat baru yang bisa ditambahkan.  \n",
    "\n",
    "Setiap kali klausa baru ditambahkan, kita menguji apakah klausa tersebut bisa di-unify dengan query.  \n",
    "Jika iya, maka substitusi yang dihasilkan dari `unify` menjadi jawaban untuk query.  \n",
    "Jika kita kehabisan kalimat untuk diinferensikan, artinya query gagal.  \n",
    "\n",
    "Fungsi `fol_fc_ask` adalah sebuah **generator** yang menghasilkan semua substitusi yang memvalidasi query.  \n",
    "\n",
    "## Fungsi `fol_fc_ask`\n",
    "\n",
    "```python\n",
    "def fol_fc_ask(kb, alpha):\n",
    "    \"\"\"\n",
    "    [Figure 9.3]\n",
    "    A simple forward-chaining algorithm.\n",
    "    \"\"\"\n",
    "    # TODO: improve efficiency\n",
    "    kb_consts = list({c for clause in kb.clauses for c in constant_symbols(clause)})\n",
    "\n",
    "    def enum_subst(p):\n",
    "        query_vars = list({v for clause in p for v in variables(clause)})\n",
    "        for assignment_list in itertools.product(kb_consts, repeat=len(query_vars)):\n",
    "            theta = {x: y for x, y in zip(query_vars, assignment_list)}\n",
    "            yield theta\n",
    "\n",
    "    # check if we can answer without new inferences\n",
    "    for q in kb.clauses:\n",
    "        phi = unify_mm(q, alpha)\n",
    "        if phi is not None:\n",
    "            yield phi\n",
    "\n",
    "    while True:\n",
    "        new = []\n",
    "        for rule in kb.clauses:\n",
    "            p, q = parse_definite_clause(rule)\n",
    "            for theta in enum_subst(p):\n",
    "                ...\n",
    "        for clause in new:\n",
    "            kb.tell(clause)\n",
    "    return None\n",
    "```\n",
    "\n",
    "## Penjelasan Fungsi\n",
    "\n",
    "* **Input:**\n",
    "\n",
    "  * `kb`: knowledge base berupa `FolKB`.\n",
    "  * `alpha`: query yang ingin diuji.\n",
    "\n",
    "* **Langkah kerja:**\n",
    "\n",
    "  1. **Ambil semua konstanta** dalam `KB` → disimpan di `kb_consts`.\n",
    "  2. **`enum_subst(p)`**: menghasilkan semua kemungkinan substitusi variabel dengan konstanta dalam `KB`.\n",
    "  3. **Cek langsung** apakah query bisa dijawab dari fakta yang sudah ada di `KB`. Jika bisa di-*unify*, hasil substitusi langsung dikembalikan.\n",
    "  4. **Loop inferensi**:\n",
    "\n",
    "     * Untuk setiap aturan (`rule`) dalam `KB`, pecah jadi premis (`p`) dan kesimpulan (`q`).\n",
    "     * Cari substitusi (`theta`) yang bisa menyatukan premis dengan fakta yang ada.\n",
    "     * Jika semua premis terpenuhi, tambahkan kesimpulan baru ke `KB`.\n",
    "  5. **Ulangi terus** hingga query terjawab atau tidak ada pengetahuan baru yang bisa ditambahkan.\n",
    "\n",
    "* **Output:**\n",
    "\n",
    "  * Menghasilkan (*yield*) semua substitusi yang membuat query benar.\n",
    "  * Jika tidak ada substitusi yang cocok, mengembalikan `None`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def fol_fc_ask(kb, alpha):\n",
      "    \"\"\"\n",
      "    [Figure 9.3]\n",
      "    A simple forward-chaining algorithm.\n",
      "    \"\"\"\n",
      "    # TODO: improve efficiency\n",
      "    kb_consts = list({c for clause in kb.clauses for c in constant_symbols(clause)})\n",
      "\n",
      "    def enum_subst(p):\n",
      "        query_vars = list({v for clause in p for v in variables(clause)})\n",
      "        for assignment_list in itertools.product(kb_consts, repeat=len(query_vars)):\n",
      "            theta = {x: y for x, y in zip(query_vars, assignment_list)}\n",
      "            yield theta\n",
      "\n",
      "    # check if we can answer without new inferences\n",
      "    for q in kb.clauses:\n",
      "        phi = unify_mm(q, alpha)\n",
      "        if phi is not None:\n",
      "            yield phi\n",
      "\n",
      "    while True:\n",
      "        new = []\n",
      "        for rule in kb.clauses:\n",
      "            p, q = parse_definite_clause(rule)\n",
      "            for theta in enum_subst(p):\n",
      "                if set(subst(theta, p)).issubset(set(kb.clauses)):\n",
      "                    q_ = subst(theta, q)\n",
      "                    if all([unify_mm(x, q_) is None for x in kb.clauses + new]):\n",
      "                        new.append(q_)\n",
      "                        phi = unify_mm(q_, alpha)\n",
      "                        if phi is not None:\n",
      "                            yield phi\n",
      "        if not new:\n",
      "            break\n",
      "        for clause in new:\n",
      "            kb.tell(clause)\n",
      "    return None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(fol_fc_ask))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mari kita cari tahu semua negara yang **hostile**.  \n",
    "Perlu dicatat bahwa kita hanya memberi tahu `KB` bahwa **Nono adalah musuh Amerika**,  \n",
    "bukan secara langsung bahwa Nono itu **hostile**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{x: Nono}]\n"
     ]
    }
   ],
   "source": [
    "answer = fol_fc_ask(crime_kb, expr('Hostile(x)'))\n",
    "print(list(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator mengembalikan satu substitusi yang menunjukkan bahwa **Nono adalah sebuah negara hostile**.  \n",
    "Perhatikan bahwa setelah kita menambahkan satu negara musuh lagi, generator akan mengembalikan **dua substitusi**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{x: Nono}, {x: JaJa}]\n"
     ]
    }
   ],
   "source": [
    "crime_kb.tell(expr('Enemy(JaJa, America)'))\n",
    "answer = fol_fc_ask(crime_kb, expr('Hostile(x)'))\n",
    "print(list(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Catatan:**  \n",
    "`fol_fc_ask` melakukan perubahan pada `KB` dengan cara menambahkan kalimat-kalimat baru ke dalamnya.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritma Backward Chaining\n",
    "\n",
    "Algoritma ini bekerja **mundur dari goal**, dengan merangkaikan aturan untuk menemukan fakta yang diketahui dan mendukung pembuktian.  \n",
    "\n",
    "Misalkan `goal` adalah query yang ingin kita cari substitusinya.  \n",
    "Kita mencari aturan dalam bentuk:\n",
    "\n",
    "$$\n",
    "\\text{lhs} \\implies \\text{goal}\n",
    "$$\n",
    "\n",
    "di dalam `KB` dan mencoba membuktikan `lhs`.  \n",
    "\n",
    "Mungkin terdapat beberapa klausa dalam `KB` yang menghasilkan beberapa `lhs`.  \n",
    "Cukup membuktikan **salah satu** dari klausa tersebut.  \n",
    "\n",
    "Namun, untuk membuktikan sebuah `lhs`, **semua konjungsi** dalam `lhs` dari klausa tersebut harus dibuktikan.  \n",
    "Hal ini membuat algoritma backward chaining serupa dengan pencarian **And/Or (And/Or search)**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OR\n",
    "\n",
    "Bagian *OR* dari algoritma muncul dari pilihan kita untuk memilih **setiap klausa** dalam bentuk:\n",
    "\n",
    "$$\n",
    "\\text{lhs} \\implies \\text{goal}\n",
    "$$\n",
    "\n",
    "Dengan melihat semua aturan `lhs` yang `rhs`-nya dapat di-*unify* dengan `goal`,  \n",
    "kita menghasilkan sebuah substitusi yang membuktikan semua konjungsi dalam `lhs`.  \n",
    "\n",
    "Kita menggunakan fungsi `parse_definite_clause` untuk mendapatkan `lhs` dan `rhs` dari sebuah klausa dalam bentuk:\n",
    "\n",
    "$$\n",
    "\\text{lhs} \\implies \\text{rhs}\n",
    "$$\n",
    "\n",
    "Untuk fakta atomik, `lhs` berupa **list kosong**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def fol_bc_or(kb, goal, theta):\n",
      "    for rule in kb.fetch_rules_for_goal(goal):\n",
      "        lhs, rhs = parse_definite_clause(standardize_variables(rule))\n",
      "        for theta1 in fol_bc_and(kb, lhs, unify_mm(rhs, goal, theta)):\n",
      "            yield theta1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(fol_bc_or))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fungsi `fol_bc_or`\n",
    "\n",
    "```python\n",
    "def fol_bc_or(kb, goal, theta):\n",
    "    for rule in kb.fetch_rules_for_goal(goal):\n",
    "        lhs, rhs = parse_definite_clause(standardize_variables(rule))\n",
    "        for theta1 in fol_bc_and(kb, lhs, unify_mm(rhs, goal, theta)):\n",
    "            yield theta1\n",
    "```\n",
    "\n",
    "\n",
    "## Fungsi\n",
    "\n",
    "`fol_bc_or` adalah bagian dari algoritma **backward chaining** yang menangani aspek **OR**.\n",
    "Artinya, fungsi ini mencoba membuktikan `goal` dengan melihat semua aturan yang bisa menghasilkan `goal` sebagai konsekuensinya.\n",
    "\n",
    "\n",
    "## Alur Kerja\n",
    "\n",
    "1. **Ambil aturan relevan:**\n",
    "   `kb.fetch_rules_for_goal(goal)` mengambil semua aturan dalam `KB` yang memiliki `goal` sebagai bagian dari konsekuensinya (`rhs`).\n",
    "\n",
    "2. **Standarisasi variabel:**\n",
    "   `standardize_variables(rule)` memastikan bahwa variabel dalam aturan tidak berbenturan dengan variabel lain di aturan berbeda.\n",
    "\n",
    "3. **Pisahkan klausa:**\n",
    "   `parse_definite_clause` memecah aturan menjadi `lhs` (premis) dan `rhs` (konsekuensi).\n",
    "\n",
    "4. **Unifikasi:**\n",
    "   `unify_mm(rhs, goal, theta)` mencoba melakukan unifikasi antara `rhs` dengan `goal` menggunakan substitusi awal `theta`.\n",
    "\n",
    "   * Jika unifikasi berhasil → lanjut ke tahap berikutnya.\n",
    "   * Jika gagal → aturan tersebut diabaikan.\n",
    "\n",
    "5. **Panggil `fol_bc_and`:**\n",
    "   Jika unifikasi berhasil, maka semua premis (`lhs`) dari aturan tersebut harus dibuktikan.\n",
    "   Fungsi `fol_bc_and` dipanggil untuk mencoba membuktikan semua konjungsi dalam `lhs`.\n",
    "\n",
    "6. **Hasil substitusi:**\n",
    "   Untuk setiap substitusi `theta1` yang berhasil membuktikan semua premis, hasil tersebut di-*yield* sebagai kemungkinan jawaban.\n",
    "\n",
    "## Intuisi\n",
    "\n",
    "* Fungsi ini melakukan **pencarian bercabang (OR search)**:\n",
    "  coba semua aturan yang bisa menghasilkan `goal`.\n",
    "* Jika salah satu aturan berhasil (premis-premisnya terbukti benar), maka `goal` dapat dibuktikan.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AND\n",
    "\n",
    "Bagian *AND* berkaitan dengan pembuktian **semua konjungsi** dalam `lhs`.  \n",
    "Kita perlu menemukan sebuah **substitusi** yang dapat membuktikan setiap klausa dalam daftar konjungsi tersebut.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def fol_bc_and(kb, goals, theta):\n",
      "    if theta is None:\n",
      "        pass\n",
      "    elif not goals:\n",
      "        yield theta\n",
      "    else:\n",
      "        first, rest = goals[0], goals[1:]\n",
      "        for theta1 in fol_bc_or(kb, subst(theta, first), theta):\n",
      "            for theta2 in fol_bc_and(kb, rest, theta1):\n",
      "                yield theta2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(fol_bc_and))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Fungsi `fol_bc_and`\n",
    "\n",
    "```python\n",
    "def fol_bc_and(kb, goals, theta):\n",
    "    if theta is None:\n",
    "        pass\n",
    "    elif not goals:\n",
    "        yield theta\n",
    "    else:\n",
    "        first, rest = goals[0], goals[1:]\n",
    "        for theta1 in fol_bc_or(kb, subst(theta, first), theta):\n",
    "            for theta2 in fol_bc_and(kb, rest, theta1):\n",
    "                yield theta2\n",
    "```\n",
    "\n",
    "## Fungsi\n",
    "\n",
    "`fol_bc_and` adalah bagian dari algoritma **backward chaining** yang menangani aspek **AND**.\n",
    "Artinya, fungsi ini mencoba membuktikan **semua premis (lhs)** dalam bentuk konjungsi.\n",
    "\n",
    "## Alur Kerja\n",
    "\n",
    "1. **Cek substitusi awal:**\n",
    "\n",
    "   * Jika `theta` bernilai `None` → berarti unifikasi gagal, maka tidak ada pembuktian yang bisa dilanjutkan.\n",
    "\n",
    "2. **Cek apakah goals kosong:**\n",
    "\n",
    "   * Jika `goals` kosong → semua premis sudah terbukti benar, maka `theta` dikembalikan sebagai hasil (yield).\n",
    "\n",
    "3. **Pisahkan goals:**\n",
    "\n",
    "   * Ambil klausa pertama `first` dan sisanya `rest`.\n",
    "\n",
    "4. **Substitusi dan pencarian OR:**\n",
    "\n",
    "   * Lakukan substitusi pada `first` dengan `theta`.\n",
    "   * Panggil `fol_bc_or` untuk mencoba membuktikan klausa pertama dengan aturan-aturan yang ada di `KB`.\n",
    "   * Jika berhasil, akan menghasilkan substitusi baru `theta1`.\n",
    "\n",
    "5. **Rekursif untuk sisa goals:**\n",
    "\n",
    "   * Dengan `theta1`, lanjutkan pembuktian `rest` (sisa konjungsi) dengan memanggil `fol_bc_and`.\n",
    "   * Jika semua berhasil, hasil akhir `theta2` dikembalikan.\n",
    "\n",
    "\n",
    "## Intuisi\n",
    "\n",
    "* Fungsi ini memastikan bahwa **semua premis** dari sebuah aturan benar.\n",
    "* Jika satu saja konjungsi gagal dibuktikan → keseluruhan aturan gagal.\n",
    "* Karena itu fungsi ini disebut bagian **AND** dari pencarian **And/Or search**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang fungsi utama `fol_bc_ask` memanggil `fol_bc_or` dengan substitusi awal berupa **kosong**.  \n",
    "Metode `ask` dari `FolKB` menggunakan `fol_bc_ask` dan mengambil substitusi pertama yang dikembalikan oleh generator untuk menjawab query.  \n",
    "\n",
    "Mari kita lakukan query pada knowledge base yang telah kita buat dari `clauses` untuk mencari **negara-negara hostile**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rebuild KB because running fol_fc_ask would add new facts to the KB\n",
    "crime_kb = FolKB(clauses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{v_194: Nono, x: Nono}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crime_kb.ask(expr('Hostile(x)'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CI (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
