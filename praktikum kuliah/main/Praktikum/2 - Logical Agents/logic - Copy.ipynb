{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langkah 1: Instalasi dan Import Library\n",
    "\n",
    "Pada tahap awal praktikum, perlu dipastikan seluruh library yang digunakan sudah tersedia. Oleh karena itu dilakukan proses instalasi paket tambahan serta import fungsi-fungsi yang diperlukan di notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipythonblocks in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (1.9.1)\n",
      "Requirement already satisfied: ipython>=4.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipythonblocks) (9.5.0)\n",
      "Requirement already satisfied: notebook>=4.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipythonblocks) (7.4.5)\n",
      "Requirement already satisfied: requests>=1.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipythonblocks) (2.32.5)\n",
      "Requirement already satisfied: colorama in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (0.4.6)\n",
      "Requirement already satisfied: decorator in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (2.19.2)\n",
      "Requirement already satisfied: stack_data in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipython>=4.0->ipythonblocks) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=4.0->ipythonblocks) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jedi>=0.16->ipython>=4.0->ipythonblocks) (0.8.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from notebook>=4.0->ipythonblocks) (2.17.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from notebook>=4.0->ipythonblocks) (2.27.3)\n",
      "Requirement already satisfied: jupyterlab<4.5,>=4.4.5 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from notebook>=4.0->ipythonblocks) (4.4.7)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from notebook>=4.0->ipythonblocks) (0.2.4)\n",
      "Requirement already satisfied: tornado>=6.2.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from notebook>=4.0->ipythonblocks) (6.5.2)\n",
      "Requirement already satisfied: anyio>=3.1.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (4.10.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (25.1.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (3.1.6)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (5.8.1)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (5.10.4)\n",
      "Requirement already satisfied: packaging>=22.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (25.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.22.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (3.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (27.0.2)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (2.0.5)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (0.28.1)\n",
      "Requirement already satisfied: ipykernel!=6.30.0,>=6.5.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (6.30.1)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (2.3.0)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (80.9.0)\n",
      "Requirement already satisfied: certifi in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (1.0.9)\n",
      "Requirement already satisfied: idna in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (0.16.0)\n",
      "Requirement already satisfied: babel>=2.10 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.0->ipythonblocks) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.0->ipythonblocks) (0.12.1)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.0->ipythonblocks) (4.25.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (4.15.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (25.1.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (1.8.16)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.7 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab<4.5,>=4.4.5->notebook>=4.0->ipythonblocks) (7.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jinja2>=3.0.3->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.0->ipythonblocks) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.0->ipythonblocks) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.0->ipythonblocks) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.0->ipythonblocks) (0.27.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (4.4.0)\n",
      "Requirement already satisfied: pywin32>=300 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (311)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (3.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.1.1)\n",
      "Requirement already satisfied: fqdn in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.5.1)\n",
      "Requirement already satisfied: isoduration in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.1.0)\n",
      "Requirement already satisfied: uri-template in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (24.11.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (4.13.5)\n",
      "Requirement already satisfied: bleach!=5.0.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.5.1)\n",
      "Requirement already satisfied: webencodings in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (2.21.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from requests>=1.0->ipythonblocks) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from requests>=1.0->ipythonblocks) (2.5.0)\n",
      "Requirement already satisfied: lark>=1.2.2 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.2.2)\n",
      "Requirement already satisfied: cffi>=1.0.1 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.17.1)\n",
      "Requirement already satisfied: pycparser in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (2.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (2.8)\n",
      "Requirement already satisfied: arrow>=0.15.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.0->ipythonblocks) (2.9.0.20250822)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from stack_data->ipython>=4.0->ipythonblocks) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from stack_data->ipython>=4.0->ipythonblocks) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from stack_data->ipython>=4.0->ipythonblocks) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: qpsolvers in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (4.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from qpsolvers) (2.3.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in d:\\ai_journey\\computational_intelligence\\ci\\lib\\site-packages (from qpsolvers) (1.16.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AI_Journey\\Computational_Intelligence\\CI\\Lib\\site-packages\\qpsolvers\\solvers\\__init__.py:880: UserWarning: no QP solver found on your system, you can install solvers from PyPI by ``pip install qpsolvers[open_source_solvers]``\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%pip install ipythonblocks\n",
    "%pip install qpsolvers\n",
    "from utils import *\n",
    "from logic import *\n",
    "from notebook import psource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Logical Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membuat Simbol dengan Kelas `Expr`\n",
    "\n",
    "**Tujuan:**\n",
    "Memahami bagaimana cara merepresentasikan kalimat logika sederhana menggunakan kelas `Expr`. Tahap awal dimulai dengan mendefinisikan simbol, yang merupakan bentuk paling dasar dari ekspresi logika.\n",
    "\n",
    "```python\n",
    "Symbol('x')\n",
    "```\n",
    "\n",
    "**Penjelasan:**\n",
    "\n",
    "* `Symbol('x')` → perintah ini membuat sebuah simbol bernama `x`.\n",
    "* Simbol adalah bentuk paling sederhana dari kelas `Expr`, dan digunakan sebagai representasi suatu variabel atau proposisi dalam logika.\n",
    "* Setelah dijalankan, hasil keluaran yang ditampilkan adalah **x**, artinya simbol berhasil dibuat dan dapat digunakan untuk membentuk kalimat logika yang lebih kompleks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Symbol('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Mendefinisikan Beberapa Simbol Sekaligus\n",
    "\n",
    "**Tujuan:**\n",
    "Mempelajari cara mendefinisikan lebih dari satu simbol logika dalam satu baris kode untuk mempersingkat penulisan.\n",
    "\n",
    "```python\n",
    "(x, y, P, Q, f) = symbols('x, y, P, Q, f')\n",
    "```\n",
    "\n",
    "**Penjelasan:**\n",
    "\n",
    "* `symbols('x, y, P, Q, f')` → perintah ini membuat beberapa simbol sekaligus, yaitu **x**, **y**, **P**, **Q**, dan **f**.\n",
    "* Simbol **x** dan **y** biasanya dipakai sebagai variabel, sementara **P** dan **Q** digunakan sebagai proposisi logika.\n",
    "* Simbol **f** dapat dipakai sebagai fungsi atau ekspresi lain sesuai kebutuhan.\n",
    "* Dengan cara ini, kita tidak perlu menuliskan `Symbol('x')`, `Symbol('y')`, dan seterusnya satu per satu.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x, y, P, Q, f) = symbols('x, y, P, Q, f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menggabungkan Simbol dengan Operator Logika\n",
    "\n",
    "**Tujuan:**\n",
    "Mencoba membentuk kalimat logika sederhana dengan menggunakan operator infix (`&`, `|`) dan prefix (`~`) yang tersedia di Python.\n",
    "\n",
    "```python\n",
    "P & ~Q\n",
    "```\n",
    "\n",
    "**Penjelasan:**\n",
    "\n",
    "* `P & ~Q` → membentuk kalimat logika yang artinya **P and not Q**.\n",
    "* Tanda `&` digunakan untuk operasi **AND** (konjungsi).\n",
    "* Tanda `~` digunakan untuk operasi **NOT** (negasi).\n",
    "* Dengan demikian, ekspresi ini menyatakan bahwa proposisi **P** benar **dan** proposisi **Q** tidak benar.\n",
    "* Hasil keluaran yang ditampilkan adalah bentuk logis sesuai definisi operator di kelas `Expr`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(P & ~Q)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P & ~Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melihat Properti dari Objek `Expr`\n",
    "\n",
    "**Tujuan:**\n",
    "Mengecek bagaimana sebuah kalimat logika disimpan di dalam objek `Expr`. Setiap objek `Expr` memiliki field seperti `op` (operator) dan `args` (argumen).\n",
    "\n",
    "```python\n",
    "sentence = P & ~Q\n",
    "sentence.op\n",
    "```\n",
    "\n",
    "**Penjelasan:**\n",
    "\n",
    "* `sentence = P & ~Q` → membuat sebuah ekspresi logika yang menyatakan **P and not Q**, lalu disimpan ke variabel bernama `sentence`.\n",
    "* `sentence.op` → digunakan untuk melihat operator yang dipakai di dalam ekspresi tersebut.\n",
    "* Karena ekspresinya adalah `P & ~Q`, maka nilai `sentence.op` yang ditampilkan adalah tanda **'&'**, yang berarti operator **AND**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'&'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = P & ~Q\n",
    "\n",
    "sentence.op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(P, ~Q)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pxy = P(x, y)\n",
    "\n",
    "Pxy.op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pxy.args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that the `Expr` class does not define the *logic* of Propositional Logic sentences; it just gives you a way to *represent* expressions. Think of an `Expr` as an [abstract syntax tree](https://en.wikipedia.org/wiki/Abstract_syntax_tree).  Each of the `args` in an `Expr` can be either a symbol, a number, or a nested `Expr`. We can nest these trees to any depth. Here is a deply nested `Expr`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 * f(x, y) + P(y) / 2 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operators for Constructing Logical Sentences\n",
    "\n",
    "Here is a table of the operators that can be used to form sentences. Note that we have a problem: we want to use Python operators to make sentences, so that our programs (and our interactive sessions like the one here) will show simple code. But Python does not allow implication arrows as operators, so for now we have to use a more verbose notation that Python does allow: `|'==>'|` instead of just `==>`. Alternately, you can always use the more verbose `Expr` constructor forms:\n",
    "\n",
    "| Operation                | Book | Python Infix Input | Python Output | Python `Expr` Input\n",
    "|--------------------------|----------------------|-------------------------|---|---|\n",
    "| Negation                 | &not; P      | `~P`                       | `~P` | `Expr('~', P)`\n",
    "| And                      | P &and; Q       | `P & Q`                     | `P & Q` | `Expr('&', P, Q)`\n",
    "| Or                       | P &or; Q | `P`<tt> &#124; </tt>`Q`| `P`<tt> &#124; </tt>`Q` | `Expr('`&#124;`', P, Q)`\n",
    "| Inequality (Xor)         | P &ne; Q     | `P ^ Q`                | `P ^ Q`  | `Expr('^', P, Q)`\n",
    "| Implication                  | P &rarr; Q    | `P` <tt>&#124;</tt>`'==>'`<tt>&#124;</tt> `Q`   | `P ==> Q` | `Expr('==>', P, Q)`\n",
    "| Reverse Implication      | Q &larr; P     | `Q` <tt>&#124;</tt>`'<=='`<tt>&#124;</tt> `P`  |`Q <== P` | `Expr('<==', Q, P)`\n",
    "| Equivalence            | P &harr; Q   | `P` <tt>&#124;</tt>`'<=>'`<tt>&#124;</tt> `Q`   |`P <=> Q` | `Expr('<=>', P, Q)`\n",
    "\n",
    "Here's an example of defining a sentence with an implication arrow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "~(P & Q)  |'==>'|  (~P | ~Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `expr`: a Shortcut for Constructing Sentences\n",
    "\n",
    "If the `|'==>'|` notation looks ugly to you, you can use the function `expr` instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr('~(P & Q)  ==>  (~P | ~Q)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`expr` takes a string as input, and parses it into an `Expr`. The string can contain arrow operators: `==>`, `<==`, or `<=>`, which are handled as if they were regular Python infix operators. And `expr` automatically defines any symbols, so you don't need to pre-define them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr('sqrt(b ** 2 - 4 * a * c)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now that's all you need to know about `expr`. If you are interested, we explain the messy details of how `expr` is implemented and how `|'==>'|` is handled in the appendix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propositional Knowledge Bases: `PropKB`\n",
    "\n",
    "The class `PropKB` can be used to represent a knowledge base of propositional logic sentences.\n",
    "\n",
    "We see that the class `KB` has four methods, apart from `__init__`. A point to note here: the `ask` method simply calls the `ask_generator` method. Thus, this one has already been implemented, and what you'll have to actually implement when you create your own knowledge base class (though you'll probably never need to, considering the ones we've created for you) will be the `ask_generator` function and not the `ask` function itself.\n",
    "\n",
    "The class `PropKB` now.\n",
    "* `__init__(self, sentence=None)` : The constructor `__init__` creates a single field `clauses` which will be a list of all the sentences of the knowledge base. Note that each one of these sentences will be a 'clause' i.e. a sentence which is made up of only literals and `or`s.\n",
    "* `tell(self, sentence)` : When you want to add a sentence to the KB, you use the `tell` method. This method takes a sentence, converts it to its CNF, extracts all the clauses, and adds all these clauses to the `clauses` field. So, you need not worry about `tell`ing only clauses to the knowledge base. You can `tell` the knowledge base a sentence in any form that you wish; converting it to CNF and adding the resulting clauses will be handled by the `tell` method.\n",
    "* `ask_generator(self, query)` : The `ask_generator` function is used by the `ask` function. It calls the `tt_entails` function, which in turn returns `True` if the knowledge base entails query and `False` otherwise. The `ask_generator` itself returns an empty dict `{}` if the knowledge base entails query and `None` otherwise. This might seem a little bit weird to you. After all, it makes more sense just to return a `True` or a `False` instead of the `{}` or `None` But this is done to maintain consistency with the way things are in First-Order Logic, where an `ask_generator` function is supposed to return all the substitutions that make the query true. Hence the dict, to return all these substitutions. I will be mostly be using the `ask` function which returns a `{}` or a `False`, but if you don't like this, you can always use the `ask_if_true` function which returns a `True` or a `False`.\n",
    "* `retract(self, sentence)` : This function removes all the clauses of the sentence given, from the knowledge base. Like the `tell` function, you don't have to pass clauses to remove them from the knowledge base; any sentence will do fine. The function will take care of converting that sentence to clauses and then remove those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wumpus World KB\n",
    "Let us create a `PropKB` for the wumpus world with the sentences mentioned in `section 7.4.3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wumpus_kb = PropKB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the symbols we use in our clauses.<br/>\n",
    "$P_{x, y}$ is true if there is a pit in `[x, y]`.<br/>\n",
    "$B_{x, y}$ is true if the agent senses breeze in `[x, y]`.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P11, P12, P21, P22, P31, B11, B21 = expr('P11, P12, P21, P22, P31, B11, B21')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we tell sentences based on `section 7.4.3`.<br/>\n",
    "There is no pit in `[1,1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wumpus_kb.tell(~P11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A square is breezy if and only if there is a pit in a neighboring square. This has to be stated for each square but for now, we include just the relevant squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wumpus_kb.tell(B11 | '<=>' | ((P12 | P21)))\n",
    "wumpus_kb.tell(B21 | '<=>' | ((P11 | P22 | P31)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we include the breeze percepts for the first two squares leading up to the situation in `Figure 7.3(b)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wumpus_kb.tell(~B11)\n",
    "wumpus_kb.tell(B21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the clauses stored in a `KB` by accessing its `clauses` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wumpus_kb.clauses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the equivalence $B_{1, 1} \\iff (P_{1, 2} \\lor P_{2, 1})$ was automatically converted to two implications which were inturn converted to CNF which is stored in the `KB`.<br/>\n",
    "$B_{1, 1} \\iff (P_{1, 2} \\lor P_{2, 1})$ was split into $B_{1, 1} \\implies (P_{1, 2} \\lor P_{2, 1})$ and $B_{1, 1} \\Longleftarrow (P_{1, 2} \\lor P_{2, 1})$.<br/>\n",
    "$B_{1, 1} \\implies (P_{1, 2} \\lor P_{2, 1})$ was converted to $P_{1, 2} \\lor P_{2, 1} \\lor \\neg B_{1, 1}$.<br/>\n",
    "$B_{1, 1} \\Longleftarrow (P_{1, 2} \\lor P_{2, 1})$ was converted to $\\neg (P_{1, 2} \\lor P_{2, 1}) \\lor B_{1, 1}$ which becomes $(\\neg P_{1, 2} \\lor B_{1, 1}) \\land (\\neg P_{2, 1} \\lor B_{1, 1})$ after applying De Morgan's laws and distributing the disjunction.<br/>\n",
    "$B_{2, 1} \\iff (P_{1, 1} \\lor P_{2, 2} \\lor P_{3, 2})$ is converted in similar manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge based agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A knowledge-based agent is a simple generic agent that maintains and handles a knowledge base.\n",
    "The knowledge base may initially contain some background knowledge.\n",
    "<br>\n",
    "The purpose of a KB agent is to provide a level of abstraction over knowledge-base manipulation and is to be used as a base class for agents that work on a knowledge base.\n",
    "<br>\n",
    "Given a percept, the KB agent adds the percept to its knowledge base, asks the knowledge base for the best action, and tells the knowledge base that it has in fact taken that action.\n",
    "<br>\n",
    "Our implementation of `KB-Agent` is encapsulated in a class `KB_AgentProgram` which inherits from the `KB` class.\n",
    "<br>\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psource(KBAgentProgram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The helper functions `make_percept_sentence`, `make_action_query` and `make_action_sentence` are all aptly named and as expected,\n",
    "`make_percept_sentence` makes first-order logic sentences about percepts we want our agent to receive,\n",
    "`make_action_query` asks the underlying `KB` about the action that should be taken and\n",
    "`make_action_sentence` tells the underlying `KB` about the action it has just taken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference in Propositional Knowledge Base\n",
    "In this section we will look at two algorithms to check if a sentence is entailed by the `KB`. Our goal is to decide whether $\\text{KB} \\vDash \\alpha$ for some sentence $\\alpha$.\n",
    "### Truth Table Enumeration\n",
    "It is a model-checking approach which, as the name suggests, enumerates all possible models in which the `KB` is true and checks if $\\alpha$ is also true in these models. We list the $n$ symbols in the `KB` and enumerate the $2^{n}$ models in a depth-first manner and check the truth of `KB` and $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psource(tt_check_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm basically computes every line of the truth table $KB\\implies \\alpha$ and checks if it is true everywhere.\n",
    "<br>\n",
    "If symbols are defined, the routine recursively constructs every combination of truth values for the symbols and then, \n",
    "it checks whether `model` is consistent with `kb`.\n",
    "The given models correspond to the lines in the truth table,\n",
    "which have a `true` in the KB column, \n",
    "and for these lines it checks whether the query evaluates to true\n",
    "<br>\n",
    "`result = pl_true(alpha, model)`.\n",
    "<br>\n",
    "<br>\n",
    "In short, `tt_check_all` evaluates this logical expression for each `model`\n",
    "<br>\n",
    "`pl_true(kb, model) => pl_true(alpha, model)`\n",
    "<br>\n",
    "which is logically equivalent to\n",
    "<br>\n",
    "`pl_true(kb, model) & ~pl_true(alpha, model)` \n",
    "<br>\n",
    "that is, the knowledge base and the negation of the query are logically inconsistent.\n",
    "<br>\n",
    "<br>\n",
    "`tt_entails()` just extracts the symbols from the query and calls `tt_check_all()` with the proper parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psource(tt_entails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that for two symbols P and Q, P => Q is false only when P is `True` and Q is `False`.\n",
    "Example usage of `tt_entails()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_entails(P & Q, Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P & Q is True only when both P and Q are True. Hence, (P & Q) => Q is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_entails(P | Q, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_entails(P | Q, P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we know that P | Q is true, we cannot infer the truth values of P and Q. \n",
    "Hence (P | Q) => Q is False and so is (P | Q) => P."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(A, B, C, D, E, F, G) = symbols('A, B, C, D, E, F, G')\n",
    "tt_entails(A & (B | C) & D & E & ~(F | G), A & D & E & ~F & ~G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for the KB to be true, A, D, E have to be True and F and G have to be False.\n",
    "Nothing can be said about B or C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coming back to our problem, note that `tt_entails()` takes an `Expr` which is a conjunction of clauses as the input instead of the `KB` itself. \n",
    "You can use the `ask_if_true()` method of `PropKB` which does all the required conversions. \n",
    "Let's check what `wumpus_kb` tells us about $P_{1, 1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wumpus_kb.ask_if_true(~P11), wumpus_kb.ask_if_true(P11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at Figure 7.9 we see that in all models in which the knowledge base is `True`, $P_{1, 1}$ is `False`. It makes sense that `ask_if_true()` returns `True` for $\\alpha = \\neg P_{1, 1}$ and `False` for $\\alpha = P_{1, 1}$. This begs the question, what if $\\alpha$ is `True` in only a portion of all models. Do we return `True` or `False`? This doesn't rule out the possibility of $\\alpha$ being `True` but it is not entailed by the `KB` so we return `False` in such cases. We can see this is the case for $P_{2, 2}$ and $P_{3, 1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wumpus_kb.ask_if_true(~P22), wumpus_kb.ask_if_true(P22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof by Resolution\n",
    "Recall that our goal is to check whether $\\text{KB} \\vDash \\alpha$ i.e. is $\\text{KB} \\implies \\alpha$ true in every model. Suppose we wanted to check if $P \\implies Q$ is valid. We check the satisfiability of $\\neg (P \\implies Q)$, which can be rewritten as $P \\land \\neg Q$. If $P \\land \\neg Q$ is unsatisfiable, then $P \\implies Q$ must be true in all models. This gives us the result \"$\\text{KB} \\vDash \\alpha$ <em>if and only if</em> $\\text{KB} \\land \\neg \\alpha$ is unsatisfiable\".<br/>\n",
    "This technique corresponds to <em>proof by <strong>contradiction</strong></em>, a standard mathematical proof technique. We assume $\\alpha$ to be false and show that this leads to a contradiction with known axioms in $\\text{KB}$. We obtain a contradiction by making valid inferences using inference rules. In this proof we use a single inference rule, <strong>resolution</strong> which states $(l_1 \\lor \\dots \\lor l_k) \\land (m_1 \\lor \\dots \\lor m_n) \\land (l_i \\iff \\neg m_j) \\implies l_1 \\lor \\dots \\lor l_{i - 1} \\lor l_{i + 1} \\lor \\dots \\lor l_k \\lor m_1 \\lor \\dots \\lor m_{j - 1} \\lor m_{j + 1} \\lor \\dots \\lor m_n$. Applying the resolution yields us a clause which we add to the KB. We keep doing this until:\n",
    "\n",
    "* There are no new clauses that can be added, in which case $\\text{KB} \\nvDash \\alpha$.\n",
    "* Two clauses resolve to yield the <em>empty clause</em>, in which case $\\text{KB} \\vDash \\alpha$.\n",
    "\n",
    "The <em>empty clause</em> is equivalent to <em>False</em> because it arises only from resolving two complementary\n",
    "unit clauses such as $P$ and $\\neg P$ which is a contradiction as both $P$ and $\\neg P$ can't be <em>True</em> at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is  one catch however, the algorithm that implements proof by resolution cannot handle complex sentences. \n",
    "Implications and bi-implications have to be simplified into simpler clauses. \n",
    "We already know that *every sentence of a propositional logic is logically equivalent to a conjunction of clauses*.\n",
    "We will use this fact to our advantage and simplify the input sentence into the **conjunctive normal form** (CNF) which is a conjunction of disjunctions of literals.\n",
    "For eg:\n",
    "<br>\n",
    "$$(A\\lor B)\\land (\\neg B\\lor C\\lor\\neg D)\\land (D\\lor\\neg E)$$\n",
    "This is equivalent to the POS (Product of sums) form in digital electronics.\n",
    "<br>\n",
    "Here's an outline of how the conversion is done:\n",
    "1. Convert bi-implications to implications\n",
    "<br>\n",
    "$\\alpha\\iff\\beta$ can be written as $(\\alpha\\implies\\beta)\\land(\\beta\\implies\\alpha)$\n",
    "<br>\n",
    "This also applies to compound sentences\n",
    "<br>\n",
    "$\\alpha\\iff(\\beta\\lor\\gamma)$ can be written as $(\\alpha\\implies(\\beta\\lor\\gamma))\\land((\\beta\\lor\\gamma)\\implies\\alpha)$\n",
    "<br>\n",
    "2. Convert implications to their logical equivalents\n",
    "<br>\n",
    "$\\alpha\\implies\\beta$ can be written as $\\neg\\alpha\\lor\\beta$\n",
    "<br>\n",
    "3. Move negation inwards\n",
    "<br>\n",
    "CNF requires atomic literals. Hence, negation cannot appear on a compound statement.\n",
    "De Morgan's laws will be helpful here.\n",
    "<br>\n",
    "$\\neg(\\alpha\\land\\beta)\\equiv(\\neg\\alpha\\lor\\neg\\beta)$\n",
    "<br>\n",
    "$\\neg(\\alpha\\lor\\beta)\\equiv(\\neg\\alpha\\land\\neg\\beta)$\n",
    "<br>\n",
    "4. Distribute disjunction over conjunction\n",
    "<br>\n",
    "Disjunction and conjunction are distributive over each other.\n",
    "Now that we only have conjunctions, disjunctions and negations in our expression, \n",
    "we will distribute disjunctions over conjunctions wherever possible as this will give us a sentence which is a conjunction of simpler clauses, \n",
    "which is what we wanted in the first place.\n",
    "<br>\n",
    "We need a term of the form\n",
    "<br>\n",
    "$(\\alpha_{1}\\lor\\alpha_{2}\\lor\\alpha_{3}...)\\land(\\beta_{1}\\lor\\beta_{2}\\lor\\beta_{3}...)\\land(\\gamma_{1}\\lor\\gamma_{2}\\lor\\gamma_{3}...)\\land...$\n",
    "<br>\n",
    "<br>\n",
    "The `to_cnf` function executes this conversion using helper subroutines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psource(to_cnf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`to_cnf` calls three subroutines.\n",
    "<br>\n",
    "`eliminate_implications` converts bi-implications and implications to their logical equivalents.\n",
    "<br>\n",
    "`move_not_inwards` removes negations from compound statements and moves them inwards using De Morgan's laws.\n",
    "<br>\n",
    "`distribute_and_over_or` distributes disjunctions over conjunctions.\n",
    "<br>\n",
    "Run the cell below for implementation details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psource(eliminate_implications)\n",
    "psource(move_not_inwards)\n",
    "psource(distribute_and_over_or)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert some sentences to see how it works\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C, D = expr('A, B, C, D')\n",
    "to_cnf(A |'<=>'| B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_cnf(A |'<=>'| (B & C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_cnf(A & (B | (C & D)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_cnf((A |'<=>'| ~B) |'==>'| (C | ~D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coming back to our resolution problem, we can see how the `to_cnf` function is utilized here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psource(pl_resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_resolution(wumpus_kb, ~P11), pl_resolution(wumpus_kb, P11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_resolution(wumpus_kb, ~P22), pl_resolution(wumpus_kb, P22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward and backward chaining\n",
    "Previously, we said we will look at two algorithms to check if a sentence is entailed by the `KB`. Here's a third one. \n",
    "The difference here is that our goal now is to determine if a knowledge base of definite clauses entails a single proposition symbol *q* - the query.\n",
    "There is a catch however - the knowledge base can only contain **Horn clauses**.\n",
    "<br>\n",
    "#### Horn Clauses\n",
    "Horn clauses can be defined as a *disjunction* of *literals* with **at most** one positive literal. \n",
    "<br>\n",
    "A Horn clause with exactly one positive literal is called a *definite clause*.\n",
    "<br>\n",
    "A Horn clause might look like \n",
    "<br>\n",
    "$\\neg a\\lor\\neg b\\lor\\neg c\\lor\\neg d... \\lor z$\n",
    "<br>\n",
    "This, coincidentally, is also a definite clause.\n",
    "<br>\n",
    "Using De Morgan's laws, the example above can be simplified to \n",
    "<br>\n",
    "$a\\land b\\land c\\land d ... \\implies z$\n",
    "<br>\n",
    "This seems like a logical representation of how humans process known data and facts. \n",
    "Assuming percepts `a`, `b`, `c`, `d` ... to be true simultaneously, we can infer `z` to also be true at that point in time. \n",
    "There are some interesting aspects of Horn clauses that make algorithmic inference or *resolution* easier.\n",
    "- Definite clauses can be written as implications:\n",
    "<br>\n",
    "The most important simplification a definite clause provides is that it can be written as an implication.\n",
    "The premise (or the knowledge that leads to the implication) is a conjunction of positive literals.\n",
    "The conclusion (the implied statement) is also a positive literal.\n",
    "The sentence thus becomes easier to understand.\n",
    "The premise and the conclusion are conventionally called the *body* and the *head* respectively.\n",
    "A single positive literal is called a *fact*.\n",
    "- Forward chaining and backward chaining can be used for inference from Horn clauses:\n",
    "<br>\n",
    "Forward chaining is semantically identical to `AND-OR-Graph-Search` from the chapter on search algorithms.\n",
    "Implementational details will be explained shortly.\n",
    "- Deciding entailment with Horn clauses is linear in size of the knowledge base:\n",
    "<br>\n",
    "Surprisingly, the forward and backward chaining algorithms traverse each element of the knowledge base at most once, greatly simplifying the problem.\n",
    "<br>\n",
    "<br>\n",
    "The function `pl_fc_entails` implements forward chaining to see if a knowledge base `KB` entails a symbol `q`.\n",
    "<br>\n",
    "Before we proceed further, note that `pl_fc_entails` doesn't use an ordinary `KB` instance. \n",
    "The knowledge base here is an instance of the `PropDefiniteKB` class, derived from the `PropKB` class, \n",
    "but modified to store definite clauses.\n",
    "<br>\n",
    "The main point of difference arises in the inclusion of a helper method to `PropDefiniteKB` that returns a list of clauses in KB that have a given symbol `p` in their premise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psource(PropDefiniteKB.clauses_with_premise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now have a look at the `pl_fc_entails` algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psource(pl_fc_entails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function accepts a knowledge base `KB` (an instance of `PropDefiniteKB`) and a query `q` as inputs.\n",
    "<br>\n",
    "<br>\n",
    "`count` initially stores the number of symbols in the premise of each sentence in the knowledge base.\n",
    "<br>\n",
    "The `conjuncts` helper function separates a given sentence at conjunctions.\n",
    "<br>\n",
    "`inferred` is initialized as a *boolean* defaultdict. \n",
    "This will be used later to check if we have inferred all premises of each clause of the agenda.\n",
    "<br>\n",
    "`agenda` initially stores a list of clauses that the knowledge base knows to be true.\n",
    "The `is_prop_symbol` helper function checks if the given symbol is a valid propositional logic symbol.\n",
    "<br>\n",
    "<br>\n",
    "We now iterate through `agenda`, popping a symbol `p` on each iteration.\n",
    "If the query `q` is the same as `p`, we know that entailment holds.\n",
    "<br>\n",
    "The agenda is processed, reducing `count` by one for each implication with a premise `p`.\n",
    "A conclusion is added to the agenda when `count` reaches zero. This means we know all the premises of that particular implication to be true.\n",
    "<br>\n",
    "`clauses_with_premise` is a helpful method of the `PropKB` class.\n",
    "It returns a list of clauses in the knowledge base that have `p` in their premise.\n",
    "<br>\n",
    "<br>\n",
    "Now that we have an idea of how this function works, let's see a few examples of its usage, but we first need to define our knowledge base. We assume we know the following clauses to be true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clauses = ['(B & F)==>E', \n",
    "           '(A & E & F)==>G', \n",
    "           '(B & C)==>F', \n",
    "           '(A & B)==>D', \n",
    "           '(E & F)==>H', \n",
    "           '(H & I)==>J',\n",
    "           'A', \n",
    "           'B', \n",
    "           'C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now `tell` this information to our knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "definite_clauses_KB = PropDefiniteKB()\n",
    "for clause in clauses:\n",
    "    definite_clauses_KB.tell(expr(clause))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check if our knowledge base entails the following queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_fc_entails(definite_clauses_KB, expr('G'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_fc_entails(definite_clauses_KB, expr('H'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_fc_entails(definite_clauses_KB, expr('I'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_fc_entails(definite_clauses_KB, expr('J'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effective Propositional Model Checking\n",
    "\n",
    "The previous segments elucidate the algorithmic procedure for model checking. \n",
    "In this segment, we look at ways of making them computationally efficient.\n",
    "<br>\n",
    "The problem we are trying to solve is conventionally called the _propositional satisfiability problem_, abbreviated as the _SAT_ problem.\n",
    "In layman terms, if there exists a model that satisfies a given Boolean formula, the formula is called satisfiable.\n",
    "<br>\n",
    "The SAT problem was the first problem to be proven _NP-complete_.\n",
    "The main characteristics of an NP-complete problem are:\n",
    "- Given a solution to such a problem, it is easy to verify if the solution solves the problem.\n",
    "- The time required to actually solve the problem using any known algorithm increases exponentially with respect to the size of the problem.\n",
    "<br>\n",
    "<br>\n",
    "Due to these properties, heuristic and approximational methods are often applied to find solutions to these problems.\n",
    "<br>\n",
    "It is extremely important to be able to solve large scale SAT problems efficiently because \n",
    "many combinatorial problems in computer science can be conveniently reduced to checking the satisfiability of a propositional sentence under some constraints.\n",
    "<br>\n",
    "We will introduce two new algorithms that perform propositional model checking in a computationally effective way.\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. DPLL (Davis-Putnam-Logeman-Loveland) algorithm\n",
    "This algorithm is very similar to Backtracking-Search.\n",
    "It recursively enumerates possible models in a depth-first fashion with the following improvements over algorithms like `tt_entails`:\n",
    "1. Early termination:\n",
    "<br>\n",
    "In certain cases, the algorithm can detect the truth value of a statement using just a partially completed model.\n",
    "For example, $(P\\lor Q)\\land(P\\lor R)$ is true if P is true, regardless of other variables.\n",
    "This reduces the search space significantly.\n",
    "2. Pure symbol heuristic:\n",
    "<br>\n",
    "A symbol that has the same sign (positive or negative) in all clauses is called a _pure symbol_.\n",
    "It isn't difficult to see that any satisfiable model will have the pure symbols assigned such that its parent clause becomes _true_.\n",
    "For example, $(P\\lor\\neg Q)\\land(\\neg Q\\lor\\neg R)\\land(R\\lor P)$ has P and Q as pure symbols\n",
    "and for the sentence to be true, P _has_ to be true and Q _has_ to be false.\n",
    "The pure symbol heuristic thus simplifies the problem a bit.\n",
    "3. Unit clause heuristic:\n",
    "<br>\n",
    "In the context of DPLL, clauses with just one literal and clauses with all but one _false_ literals are called unit clauses.\n",
    "If a clause is a unit clause, it can only be satisfied by assigning the necessary value to make the last literal true.\n",
    "We have no other choice.\n",
    "<br>\n",
    "Assigning one unit clause can create another unit clause.\n",
    "For example, when P is false, $(P\\lor Q)$ becomes a unit clause, causing _true_ to be assigned to Q.\n",
    "A series of forced assignments derived from previous unit clauses is called _unit propagation_.\n",
    "In this way, this heuristic simplifies the problem further.\n",
    "<br>\n",
    "The algorithm often employs other tricks to scale up to large problems.\n",
    "However, these tricks are currently out of the scope of this notebook. Refer to section 7.6 of the book for more details.\n",
    "<br>\n",
    "<br>\n",
    "Let's have a look at the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psource(dpll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm uses the ideas described above to check satisfiability of a sentence in propositional logic.\n",
    "It recursively calls itself, simplifying the problem at each step. It also uses helper functions `find_pure_symbol` and `find_unit_clause` to carry out steps 2 and 3 above.\n",
    "<br>\n",
    "The `dpll_satisfiable` helper function converts the input clauses to _conjunctive normal form_ and calls the `dpll` function with the correct parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psource(dpll_satisfiable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see a few examples of usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A, B, C, D = expr('A, B, C, D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpll_satisfiable(A & B & ~C & D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple case to highlight that the algorithm actually works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpll_satisfiable((A & B) | (C & ~A) | (B & ~D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a particular symbol isn't present in the solution, \n",
    "it means that the solution is independent of the value of that symbol.\n",
    "In this case, the solution is independent of A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpll_satisfiable(A |'<=>'| B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpll_satisfiable((A |'<=>'| B) |'==>'| (C & ~A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpll_satisfiable((A | (B & C)) |'<=>'| ((A | B) & (A | C)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. WalkSAT algorithm\n",
    "This algorithm is very similar to Hill climbing.\n",
    "On every iteration, the algorithm picks an unsatisfied clause and flips a symbol in the clause.\n",
    "This is similar to finding a neighboring state in the `hill_climbing` algorithm.\n",
    "<br>\n",
    "The symbol to be flipped is decided by an evaluation function that counts the number of unsatisfied clauses.\n",
    "Sometimes, symbols are also flipped randomly to avoid local optima. A subtle balance between greediness and randomness is required. Alternatively, some versions of the algorithm restart with a completely new random assignment if no solution has been found for too long as a way of getting out of local minima of numbers of unsatisfied clauses.\n",
    "<br>\n",
    "<br>\n",
    "Let's have a look at the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psource(WalkSAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function takes three arguments:\n",
    "<br>\n",
    "1. The `clauses` we want to satisfy.\n",
    "<br>\n",
    "2. The probability `p` of randomly changing a symbol.\n",
    "<br>\n",
    "3. The maximum number of flips (`max_flips`) the algorithm will run for. If the clauses are still unsatisfied, the algorithm returns `None` to denote failure.\n",
    "<br>\n",
    "The algorithm is identical in concept to Hill climbing and the code isn't difficult to understand.\n",
    "<br>\n",
    "<br>\n",
    "Let's see a few examples of usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A, B, C, D = expr('A, B, C, D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WalkSAT([A, B, ~C, D], 0.5, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple case to show that the algorithm converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WalkSAT([A & B, A & C], 0.5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WalkSAT([A & B, C & D, C & B], 0.5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WalkSAT([A & B, C | D, ~(D | B)], 0.5, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one doesn't give any output because WalkSAT did not find any model where these clauses hold. We can solve these clauses to see that they together form a contradiction and hence, it isn't supposed to have a solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One point of difference between this algorithm and the `dpll_satisfiable` algorithms is that both these algorithms take inputs differently. \n",
    "For WalkSAT to take complete sentences as input, \n",
    "we can write a helper function that converts the input sentence into conjunctive normal form and then calls WalkSAT with the list of conjuncts of the CNF form of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def WalkSAT_CNF(sentence, p=0.5, max_flips=10000):\n",
    "    return WalkSAT(conjuncts(to_cnf(sentence)), 0, max_flips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can call `WalkSAT_CNF` and `DPLL_Satisfiable` with the same arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WalkSAT_CNF((A & B) | (C & ~A) | (B & ~D), 0.5, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works!\n",
    "<br>\n",
    "Notice that the solution generated by WalkSAT doesn't omit variables that the sentence doesn't depend upon. \n",
    "If the sentence is independent of a particular variable, the solution contains a random value for that variable because of the stochastic nature of the algorithm.\n",
    "<br>\n",
    "<br>\n",
    "Let's compare the runtime of WalkSAT and DPLL for a few cases. We will use the `%%timeit` magic to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_1 = A |'<=>'| B\n",
    "sentence_2 = (A & B) | (C & ~A) | (B & ~D)\n",
    "sentence_3 = (A | (B & C)) |'<=>'| ((A | B) & (A | C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "dpll_satisfiable(sentence_1)\n",
    "dpll_satisfiable(sentence_2)\n",
    "dpll_satisfiable(sentence_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "WalkSAT_CNF(sentence_1)\n",
    "WalkSAT_CNF(sentence_2)\n",
    "WalkSAT_CNF(sentence_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On an average, for solvable cases, `WalkSAT` is quite faster than `dpll` because, for a small number of variables, \n",
    "`WalkSAT` can reduce the search space significantly. \n",
    "Results can be different for sentences with more symbols though.\n",
    "Feel free to play around with this to understand the trade-offs of these algorithms better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SATPlan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we show how to make plans by logical inference. The basic idea is very simple. It includes the following three steps:\n",
    "1. Constuct a sentence that includes:\n",
    "    1. A colection of assertions about the initial state.\n",
    "    2. The successor-state axioms for all the possible actions at each time up to some maximum time t.\n",
    "    3. The assertion that the goal is achieved at time t.\n",
    "2. Present the whole sentence to a SAT solver.\n",
    "3. Assuming a model is found, extract from the model those variables that represent actions and are assigned true. Together they represent a plan to achieve the goals.\n",
    "\n",
    "\n",
    "Lets have a look at the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psource(SAT_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see few examples of its usage. First we define a transition and then call `SAT_plan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition = {'A': {'Left': 'A', 'Right': 'B'},\n",
    "            'B': {'Left': 'A', 'Right': 'C'},\n",
    "            'C': {'Left': 'B', 'Right': 'C'}}\n",
    "\n",
    "\n",
    "print(SAT_plan('A', transition, 'C', 2)) \n",
    "print(SAT_plan('A', transition, 'B', 3))\n",
    "print(SAT_plan('C', transition, 'A', 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us do the same for another transition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition = {(0, 0): {'Right': (0, 1), 'Down': (1, 0)},\n",
    "            (0, 1): {'Left': (1, 0), 'Down': (1, 1)},\n",
    "            (1, 0): {'Right': (1, 0), 'Up': (1, 0), 'Left': (1, 0), 'Down': (1, 0)},\n",
    "            (1, 1): {'Left': (1, 0), 'Up': (0, 1)}}\n",
    "\n",
    "\n",
    "print(SAT_plan((0, 0), transition, (1, 1), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First-Order Logic Knowledge Bases: `FolKB`\n",
    "\n",
    "The class `FolKB` can be used to represent a knowledge base of First-order logic sentences. You would initialize and use it the same way as you would for `PropKB` except that the clauses are first-order definite clauses. We will see how to write such clauses to create a database and query them in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criminal KB\n",
    "In this section we create a `FolKB` based on the following paragraph.<br/>\n",
    "<em>The law says that it is a crime for an American to sell weapons to hostile nations. The country Nono, an enemy of America, has some missiles, and all of its missiles were sold to it by Colonel West, who is American.</em><br/>\n",
    "The first step is to extract the facts and convert them into first-order definite clauses. Extracting the facts from data alone is a challenging task. Fortunately, we have a small paragraph and can do extraction and conversion manually. We'll store the clauses in list aptly named `clauses`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clauses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>“... it is a crime for an American to sell weapons to hostile nations”</em><br/>\n",
    "The keywords to look for here are 'crime', 'American', 'sell', 'weapon' and 'hostile'. We use predicate symbols to make meaning of them.\n",
    "\n",
    "* `Criminal(x)`: `x` is a criminal\n",
    "* `American(x)`: `x` is an American\n",
    "* `Sells(x ,y, z)`: `x` sells `y` to `z`\n",
    "* `Weapon(x)`: `x` is a weapon\n",
    "* `Hostile(x)`: `x` is a hostile nation\n",
    "\n",
    "Let us now combine them with appropriate variable naming to depict the meaning of the sentence. The criminal `x` is also the American `x` who sells weapon `y` to `z`, which is a hostile nation.\n",
    "\n",
    "$\\text{American}(x) \\land \\text{Weapon}(y) \\land \\text{Sells}(x, y, z) \\land \\text{Hostile}(z) \\implies \\text{Criminal} (x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clauses.append(expr(\"(American(x) & Weapon(y) & Sells(x, y, z) & Hostile(z)) ==> Criminal(x)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>\"The country Nono, an enemy of America\"</em><br/>\n",
    "We now know that Nono is an enemy of America. We represent these nations using the constant symbols `Nono` and `America`. the enemy relation is show using the predicate symbol `Enemy`.\n",
    "\n",
    "$\\text{Enemy}(\\text{Nono}, \\text{America})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clauses.append(expr(\"Enemy(Nono, America)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>\"Nono ... has some missiles\"</em><br/>\n",
    "This states the existence of some missile which is owned by Nono. $\\exists x \\text{Owns}(\\text{Nono}, x) \\land \\text{Missile}(x)$. We invoke existential instantiation to introduce a new constant `M1` which is the missile owned by Nono.\n",
    "\n",
    "$\\text{Owns}(\\text{Nono}, \\text{M1}), \\text{Missile}(\\text{M1})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clauses.append(expr(\"Owns(Nono, M1)\"))\n",
    "clauses.append(expr(\"Missile(M1)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<em>\"All of its missiles were sold to it by Colonel West\"</em><br/>\n",
    "If Nono owns something and it classifies as a missile, then it was sold to Nono by West.\n",
    "\n",
    "$\\text{Missile}(x) \\land \\text{Owns}(\\text{Nono}, x) \\implies \\text{Sells}(\\text{West}, x, \\text{Nono})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clauses.append(expr(\"(Missile(x) & Owns(Nono, x)) ==> Sells(West, x, Nono)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>\"West, who is American\"</em><br/>\n",
    "West is an American.\n",
    "\n",
    "$\\text{American}(\\text{West})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clauses.append(expr(\"American(West)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also know, from our understanding of language, that missiles are weapons and that an enemy of America counts as “hostile”.\n",
    "\n",
    "$\\text{Missile}(x) \\implies \\text{Weapon}(x), \\text{Enemy}(x, \\text{America}) \\implies \\text{Hostile}(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clauses.append(expr(\"Missile(x) ==> Weapon(x)\"))\n",
    "clauses.append(expr(\"Enemy(x, America) ==> Hostile(x)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have converted the information into first-order definite clauses we can create our first-order logic knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crime_kb = FolKB(clauses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `subst` helper function substitutes variables with given values in first-order logic statements.\n",
    "This will be useful in later algorithms.\n",
    "It's implementation is quite simple and self-explanatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psource(subst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of how `subst` can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subst({x: expr('Nono'), y: expr('M1')}, expr('Owns(x, y)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference in First-Order Logic\n",
    "In this section we look at a forward chaining and a backward chaining algorithm for `FolKB`. Both aforementioned algorithms rely on a process called <strong>unification</strong>, a key component of all first-order inference algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unification\n",
    "We sometimes require finding substitutions that make different logical expressions look identical. This process, called unification, is done by the `unify` algorithm. It takes as input two sentences and returns a <em>unifier</em> for them if one exists. A unifier is a dictionary which stores the substitutions required to make the two sentences identical. It does so by recursively unifying the components of a sentence, where the unification of a variable symbol `var` with a constant symbol `Const` is the mapping `{var: Const}`. Let's look at a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unify(expr('x'), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unify(expr('A(x)'), expr('A(B)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unify(expr('Cat(x) & Dog(Dobby)'), expr('Cat(Bella) & Dog(y)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cases where there is no possible substitution that unifies the two sentences the function return `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unify(expr('Cat(x)'), expr('Dog(Dobby)')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to take care we do not unintentionally use the same variable name. Unify treats them as a single variable which prevents it from taking multiple value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unify(expr('Cat(x) & Dog(Dobby)'), expr('Cat(Bella) & Dog(x)')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Chaining Algorithm\n",
    "We consider the simple forward-chaining algorithm presented in <em>Figure 9.3</em>. We look at each rule in the knowledge base and see if the premises can be satisfied. This is done by finding a substitution which unifies each of the premise with a clause in the `KB`. If we are able to unify the premises, the conclusion (with the corresponding substitution) is added to the `KB`. This inferencing process is repeated until either the query can be answered or till no new sentences can be added. We test if the newly added clause unifies with the query in which case the substitution yielded by `unify` is an answer to the query. If we run out of sentences to infer, this means the query was a failure.\n",
    "\n",
    "The function `fol_fc_ask` is a generator which yields all substitutions which validate the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psource(fol_fc_ask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out all the hostile nations. Note that we only told the `KB` that Nono was an enemy of America, not that it was hostile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = fol_fc_ask(crime_kb, expr('Hostile(x)'))\n",
    "print(list(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generator returned a single substitution which says that Nono is a hostile nation. See how after adding another enemy nation the generator returns two substitutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_kb.tell(expr('Enemy(JaJa, America)'))\n",
    "answer = fol_fc_ask(crime_kb, expr('Hostile(x)'))\n",
    "print(list(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><em>Note</em>:</strong> `fol_fc_ask` makes changes to the `KB` by adding sentences to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Chaining Algorithm\n",
    "This algorithm works backward from the goal, chaining through rules to find known facts that support the proof. Suppose `goal` is the query we want to find the substitution for. We find rules of the form $\\text{lhs} \\implies \\text{goal}$ in the `KB` and try to prove `lhs`. There may be multiple clauses in the `KB` which give multiple `lhs`. It is sufficient to prove only one of these. But to prove a `lhs` all the conjuncts in the `lhs` of the clause must be proved. This makes it similar to <em>And/Or</em> search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OR\n",
    "The <em>OR</em> part of the algorithm comes from our choice to select any clause of the form $\\text{lhs} \\implies \\text{goal}$. Looking at all rules's `lhs` whose `rhs` unify with the `goal`, we yield a substitution which proves all the conjuncts in the `lhs`. We use `parse_definite_clause` to attain `lhs` and `rhs` from a clause of the form $\\text{lhs} \\implies \\text{rhs}$. For atomic facts the `lhs` is an empty list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psource(fol_bc_or)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AND\n",
    "The <em>AND</em> corresponds to proving all the conjuncts in the `lhs`. We need to find a substitution which proves each <em>and</em> every clause in the list of conjuncts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psource(fol_bc_and)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the main function `fl_bc_ask` calls `fol_bc_or` with substitution initialized as empty. The `ask` method of `FolKB` uses `fol_bc_ask` and fetches the first substitution returned by the generator to answer query. Let's query the knowledge base we created from `clauses` to find hostile nations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rebuild KB because running fol_fc_ask would add new facts to the KB\n",
    "crime_kb = FolKB(clauses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_kb.ask(expr('Hostile(x)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice some new variables in the substitution. They are introduced to standardize the variable names to prevent naming problems as discussed in the [Unification section](#Unification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: The Implementation of `|'==>'|`\n",
    "\n",
    "Consider the `Expr` formed by this syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P |'==>'| ~Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the funny `|'==>'|` syntax? The trick is that \"`|`\" is just the regular Python or-operator, and so is exactly equivalent to this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(P | '==>') | ~Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, there are two applications of or-operators. Here's the first one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P | '==>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is going on here is that the `__or__` method of `Expr` serves a dual purpose. If the right-hand-side is another `Expr` (or a number), then the result is an `Expr`, as in `(P | Q)`. But if the right-hand-side is a string, then the string is taken to be an operator, and we create a node in the abstract syntax tree corresponding to a partially-filled  `Expr`, one where we know the left-hand-side is `P` and the operator is `==>`, but we don't yet know the right-hand-side.\n",
    "\n",
    "The `PartialExpr` class has an `__or__` method that says to create an `Expr` node with the right-hand-side filled in. Here we can see the combination of the `PartialExpr` with `Q` to create a complete `Expr`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial = PartialExpr('==>', P) \n",
    "partial | ~Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This  [trick](http://code.activestate.com/recipes/384122-infix-operators/) is due to [Ferdinand Jamitzky](http://code.activestate.com/recipes/users/98863/), with a modification by [C. G. Vedant](https://github.com/Chipe1),\n",
    "who suggested using a string inside the or-bars.\n",
    "\n",
    "## Appendix: The Implementation of `expr`\n",
    "\n",
    "How does `expr` parse a string into an `Expr`? It turns out there are two tricks (besides the Jamitzky/Vedant trick):\n",
    "\n",
    "1. We do a string substitution, replacing \"`==>`\" with \"`|'==>'|`\" (and likewise for other operators).\n",
    "2. We `eval` the resulting string in an environment in which every identifier\n",
    "is bound to a symbol with that identifier as the `op`.\n",
    "\n",
    "In other words,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr('~(P & Q)  ==>  (~P | ~Q)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is equivalent to doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P, Q = symbols('P, Q')\n",
    "~(P & Q)  |'==>'|  (~P | ~Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to beware of: this puts `==>` at the same precedence level as `\"|\"`, which is not quite right. For example, we get this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P & Q  |'==>'|  P | Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is probably not what we meant; when in doubt, put in extra parens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(P & Q)  |'==>'|  (P | Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook import Canvas_fol_bc_ask\n",
    "canvas_bc_ask = Canvas_fol_bc_ask('canvas_bc_ask', crime_kb, expr('Criminal(x)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Authors\n",
    "\n",
    "This notebook by [Chirag Vartak](https://github.com/chiragvartak) and [Peter Norvig](https://github.com/norvig).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CI (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
